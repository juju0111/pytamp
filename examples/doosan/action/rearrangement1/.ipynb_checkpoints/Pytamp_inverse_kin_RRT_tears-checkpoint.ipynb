{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30835fd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 20:21:45.862373: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "usage: ipykernel_launcher.py [-h] [--budgets T] [--max_depth H] [--seed i]\n",
      "                             [--algo alg] [--debug_mode DEBUG_MODE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/juju/.local/share/jupyter/runtime/kernel-febcd94a-d83a-41a4-b1be-6f34d75052d7.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************** \u001b[92mLogical States\u001b[0m ***********************\n",
      "OrderedDict([('ben_cube0',\n",
      "              {'on': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043])}),\n",
      "             ('bottle0',\n",
      "              {'on': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043])}),\n",
      "             ('can0',\n",
      "              {'on': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043])}),\n",
      "             ('cereal0',\n",
      "              {'on': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043])}),\n",
      "             ('table',\n",
      "              {'static': True,\n",
      "               'support': [\u001b[95mObject\u001b[0m(name=ben_cube0, pos=[0.39587317 0.03565069 0.83529998]),\n",
      "                           \u001b[95mObject\u001b[0m(name=bottle0, pos=[ 0.62089307 -0.32701184  0.87515735]),\n",
      "                           \u001b[95mObject\u001b[0m(name=can0, pos=[ 0.45938771 -0.22735796  0.85059666]),\n",
      "                           \u001b[95mObject\u001b[0m(name=cereal0, pos=[ 0.57663268 -0.00691541  0.88526188])]}),\n",
      "             ('panda_gripper', {'holding': None})])\n",
      "***************************************************************\n",
      "\n",
      "*********************** \u001b[92mLogical States\u001b[0m ***********************\n",
      "OrderedDict([('ben_cube0',\n",
      "              {'on': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043])}),\n",
      "             ('bottle0',\n",
      "              {'on': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043])}),\n",
      "             ('can0',\n",
      "              {'on': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043])}),\n",
      "             ('cereal0',\n",
      "              {'on': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043])}),\n",
      "             ('table',\n",
      "              {'static': True,\n",
      "               'support': [\u001b[95mObject\u001b[0m(name=ben_cube0, pos=[ 0.55190957 -0.03581815  0.83529998]),\n",
      "                           \u001b[95mObject\u001b[0m(name=bottle0, pos=[ 0.41998304 -0.12788834  0.87515735]),\n",
      "                           \u001b[95mObject\u001b[0m(name=can0, pos=[ 0.39348095 -0.01815785  0.85059666]),\n",
      "                           \u001b[95mObject\u001b[0m(name=cereal0, pos=[ 0.52829008 -0.30755704  0.88526188])]}),\n",
      "             ('panda_gripper', {'holding': None})])\n",
      "***************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os, time\n",
    "\n",
    "from pykin.utils import plot_utils as p_utils\n",
    "\n",
    "from pytamp.benchmark import Rearrange1\n",
    "from pytamp.benchmark.rearrange1 import make_scene\n",
    "from pytamp.search.mcts_for_rearragement import MCTS_rearrangement\n",
    "from pytamp.utils import point_cloud_utils as pc_utils\n",
    "\n",
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser(description=\"Test Rearragement 1.\")\n",
    "    parser.add_argument(\"--budgets\", metavar=\"T\", type=int, default=30, help=\"Horizon\")\n",
    "    parser.add_argument(\"--max_depth\", metavar=\"H\", type=int, default=16, help=\"Max depth\")\n",
    "#     parser.add_argument(\"--seed\", metavar=\"i\", type=int, default=7, help=\"A random seed\")\n",
    "#     parser.add_argument(\"--seed\", metavar=\"i\", type=int, default=17, help=\"A random seed\")\n",
    "    parser.add_argument(\"--seed\", metavar=\"i\", type=int, default=22, help=\"A random seed\")\n",
    "    parser.add_argument(\n",
    "        \"--algo\",\n",
    "        metavar=\"alg\",\n",
    "        type=str,\n",
    "        default=\"bai_perturb\",\n",
    "        choices=[\"bai_perturb\", \"bai_ucb\", \"uct\", \"random\", \"greedy\"],\n",
    "        help=\"Choose one (bai_perturb, bai_ucb, uct)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--debug_mode\", default=False, type=lambda x: (str(x).lower() == \"true\"), help=\"Debug mode\"\n",
    "    )\n",
    "#     parser.add_argument(\"--box_number\", metavar=\"N\", type=int, default=6, help=\"Box Number(6 or less)\")\n",
    "    try:\n",
    "        args = parser.parse_args() #call from command line\n",
    "    except:\n",
    "        args = parser.parse_args(args=[]) #call from notebook\n",
    "    return args \n",
    "\n",
    "args = get_parser() \n",
    "\n",
    "debug_mode = args.debug_mode\n",
    "# debug_mode = True\n",
    "budgets = args.budgets\n",
    "max_depth = args.max_depth\n",
    "algo = args.algo\n",
    "seed = args.seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "object_names, init_scene, goal_scene = make_scene()\n",
    "rearrangement1 = Rearrange1('panda', object_names, init_scene, goal_scene, is_pyplot=False)\n",
    "\n",
    "final_level_1_values = []\n",
    "final_level_2_values = []\n",
    "final_optimal_nodes = []\n",
    "final_pnp_all_joint_paths = []\n",
    "final_pick_all_objects = []\n",
    "final_place_all_object_poses = []\n",
    "\n",
    "# final_optimal_trees = []\n",
    "c_list = 10 ** np.linspace(-2, 2.0, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97474979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'table': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043]), 'ben_cube0': \u001b[95mObject\u001b[0m(name=ben_cube0, pos=[0.39587317 0.03565069 0.83529998]), 'bottle0': \u001b[95mObject\u001b[0m(name=bottle0, pos=[ 0.62089307 -0.32701184  0.87515735]), 'can0': \u001b[95mObject\u001b[0m(name=can0, pos=[ 0.45938771 -0.22735796  0.85059666]), 'cereal0': \u001b[95mObject\u001b[0m(name=cereal0, pos=[ 0.57663268 -0.00691541  0.88526188])}\n",
      "{'table': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043]), 'ben_cube0': \u001b[95mObject\u001b[0m(name=ben_cube0, pos=[ 0.55190957 -0.03581815  0.83529998]), 'bottle0': \u001b[95mObject\u001b[0m(name=bottle0, pos=[ 0.41998304 -0.12788834  0.87515735]), 'can0': \u001b[95mObject\u001b[0m(name=can0, pos=[ 0.39348095 -0.01815785  0.85059666]), 'cereal0': \u001b[95mObject\u001b[0m(name=cereal0, pos=[ 0.52829008 -0.30755704  0.88526188])}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# #######################\n",
    "fig, ax = p_utils.init_3d_figure(name=\"Rearrangement 1\")\n",
    "# init_scene\n",
    "rearrangement1.scene_mngr.render_scene(ax)\n",
    "rearrangement1.render_axis(rearrangement1.scene_mngr)\n",
    "rearrangement1.scene_mngr.show()\n",
    "\n",
    "# goal_scene\n",
    "rearrangement1.goal_scene_mngr.render_scene(ax)\n",
    "rearrangement1.render_axis(rearrangement1.goal_scene_mngr)\n",
    "rearrangement1.goal_scene_mngr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "828caf6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = 2.5\n",
    "idx = 0\n",
    "mcts = MCTS_rearrangement(\n",
    "        scene_mngr=rearrangement1.scene_mngr,\n",
    "        init_scene=rearrangement1.init_scene,\n",
    "        sampling_method=args.algo,\n",
    "        budgets=args.budgets,\n",
    "        max_depth=args.max_depth,\n",
    "        c=c,\n",
    "        debug_mode=True,\n",
    "        use_pick_action=True,\n",
    "        consider_next_scene=False, \n",
    "    )\n",
    "mcts.only_optimize_1 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b358eaf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 1 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(22) -> S'(27) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(27) -> A(29) -> S'(30) Reward : \u001b[4m1.111\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(30) -> A(33) -> S'(35) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -11.11111111111111\n",
      "\u001b[95m[Reward]\u001b[0m S(35) -> A(None) -> S'(None) Reward : \u001b[4m-11.111\u001b[0m\n",
      "########### Running time :  2.9358348846435547 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 2 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(37) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(37) -> A(39) -> S'(40) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(40) -> A(42) -> S'(45) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(45) -> A(50) -> S'(51) Reward : \u001b[4m2.0\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(51) -> A(52) -> S'(55) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(55) -> A(56) -> S'(57) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(57) -> A(59) -> S'(61) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(61) -> A(62) -> S'(63) Reward : \u001b[4m-2.5\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(63) -> A(65) -> S'(67) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -11.11111111111111\n",
      "\u001b[95m[Reward]\u001b[0m S(67) -> A(None) -> S'(None) Reward : \u001b[4m-11.111\u001b[0m\n",
      "########### Running time :  5.3930981159210205 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 3 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(3) -> S'(70) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(70) -> A(72) -> S'(73) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(73) -> A(76) -> S'(77) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(77) -> A(78) -> S'(80) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(80) -> A(81) -> S'(84) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(84) -> A(87) -> S'(89) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(89) -> A(90) -> S'(93) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(93) -> A(95) -> S'(96) Reward : \u001b[4m1.111\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(96) -> A(99) -> S'(101) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(101) -> A(103) -> S'(104) Reward : \u001b[4m0.909\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(104) -> A(105) -> S'(108) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(108) -> A(111) -> S'(113) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(113) -> A(116) -> S'(119) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -7.6923076923076925\n",
      "\u001b[95m[Reward]\u001b[0m S(119) -> A(None) -> S'(None) Reward : \u001b[4m-7.692\u001b[0m\n",
      "########### Running time :  8.882685661315918 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 4 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(4) -> S'(120) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(120) -> A(122) -> S'(123) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(123) -> A(126) -> S'(128) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(128) -> A(130) -> S'(131) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(131) -> A(134) -> S'(135) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(135) -> A(136) -> S'(137) Reward : \u001b[4m-3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(137) -> A(140) -> S'(142) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(142) -> A(143) -> S'(144) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(144) -> A(145) -> S'(149) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(149) -> A(151) -> S'(152) Reward : \u001b[4m0.909\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(152) -> A(155) -> S'(157) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(157) -> A(161) -> S'(162) Reward : \u001b[4m0.769\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(162) -> A(163) -> S'(166) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -7.6923076923076925\n",
      "\u001b[95m[Reward]\u001b[0m S(166) -> A(None) -> S'(None) Reward : \u001b[4m-7.692\u001b[0m\n",
      "########### Running time :  12.24074673652649 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 5 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(6) -> S'(170) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(170) -> A(171) -> S'(176) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(176) -> A(181) -> S'(182) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(182) -> A(185) -> S'(186) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(186) -> A(187) -> S'(189) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(189) -> A(191) -> S'(193) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(193) -> A(194) -> S'(195) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(195) -> A(196) -> S'(203) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(203) -> A(208) -> S'(209) Reward : \u001b[4m0.909\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(209) -> A(210) -> S'(214) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(214) -> A(218) -> S'(219) Reward : \u001b[4m0.769\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(219) -> A(221) -> S'(227) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(227) -> A(229) -> S'(230) Reward : \u001b[4m0.667\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(230) -> A(231) -> S'(234) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -6.666666666666666\n",
      "\u001b[95m[Reward]\u001b[0m S(234) -> A(None) -> S'(None) Reward : \u001b[4m-6.667\u001b[0m\n",
      "########### Running time :  18.265382289886475 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 6 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(9) -> S'(237) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(237) -> A(240) -> S'(241) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(241) -> A(242) -> S'(245) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(245) -> A(246) -> S'(247) Reward : \u001b[4m-3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(247) -> A(249) -> S'(253) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(253) -> A(254) -> S'(256) Reward : \u001b[4m-1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m[Reward]\u001b[0m S(256) -> A(257) -> S'(261) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(261) -> A(263) -> S'(264) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(264) -> A(267) -> S'(268) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(268) -> A(269) -> S'(270) Reward : \u001b[4m0.769\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(270) -> A(271) -> S'(274) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(274) -> A(276) -> S'(277) Reward : \u001b[4m0.667\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(277) -> A(279) -> S'(281) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(281) -> A(285) -> S'(286) Reward : \u001b[4m0.588\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  21.953560829162598 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 7 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(11) -> S'(290) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(290) -> A(291) -> S'(293) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(293) -> A(296) -> S'(297) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(297) -> A(299) -> S'(300) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(300) -> A(303) -> S'(305) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(305) -> A(306) -> S'(307) Reward : \u001b[4m1.111\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(307) -> A(310) -> S'(311) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -11.11111111111111\n",
      "\u001b[95m[Reward]\u001b[0m S(311) -> A(None) -> S'(None) Reward : \u001b[4m-11.111\u001b[0m\n",
      "########### Running time :  23.331907987594604 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 8 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(12) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -33.333333333333336\n",
      "\u001b[95m[Reward]\u001b[0m S(12) -> A(None) -> S'(None) Reward : \u001b[4m-33.333\u001b[0m\n",
      "########### Running time :  23.389152765274048 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 9 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(13) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -33.333333333333336\n",
      "\u001b[95m[Reward]\u001b[0m S(13) -> A(None) -> S'(None) Reward : \u001b[4m-33.333\u001b[0m\n",
      "########### Running time :  23.445379495620728 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 10 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(17) -> S'(312) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(312) -> A(314) -> S'(315) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(315) -> A(318) -> S'(319) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(319) -> A(321) -> S'(322) Reward : \u001b[4m1.111\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(322) -> A(325) -> S'(328) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(328) -> A(330) -> S'(331) Reward : \u001b[4m0.909\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(331) -> A(332) -> S'(335) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(335) -> A(336) -> S'(338) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(338) -> A(341) -> S'(342) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -7.6923076923076925\n",
      "\u001b[95m[Reward]\u001b[0m S(342) -> A(None) -> S'(None) Reward : \u001b[4m-7.692\u001b[0m\n",
      "########### Running time :  26.54984998703003 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 11 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(23) -> S'(343) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -14.285714285714286\n",
      "\u001b[95m[Reward]\u001b[0m S(343) -> A(None) -> S'(None) Reward : \u001b[4m-14.286\u001b[0m\n",
      "########### Running time :  26.587518453598022 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 12 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(24) -> S'(344) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -14.285714285714286\n",
      "\u001b[95m[Reward]\u001b[0m S(344) -> A(None) -> S'(None) Reward : \u001b[4m-14.286\u001b[0m\n",
      "########### Running time :  26.65733289718628 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 13 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(22) -> S'(25) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(25) -> A(346) -> S'(347) Reward : \u001b[4m1.111\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(347) -> A(348) -> S'(351) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(351) -> A(352) -> S'(353) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(353) -> A(354) -> S'(357) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -9.09090909090909\n",
      "\u001b[95m[Reward]\u001b[0m S(357) -> A(None) -> S'(None) Reward : \u001b[4m-9.091\u001b[0m\n",
      "########### Running time :  27.733200073242188 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 14 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(22) -> S'(26) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(26) -> A(364) -> S'(365) Reward : \u001b[4m1.111\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m[Reward]\u001b[0m S(365) -> A(368) -> S'(369) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(369) -> A(370) -> S'(371) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(371) -> A(373) -> S'(377) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(377) -> A(378) -> S'(379) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(379) -> A(381) -> S'(382) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -7.6923076923076925\n",
      "\u001b[95m[Reward]\u001b[0m S(382) -> A(None) -> S'(None) Reward : \u001b[4m-7.692\u001b[0m\n",
      "########### Running time :  30.05910086631775 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 15 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(22) -> S'(27) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(27) -> A(28) -> S'(383) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(383) -> A(385) -> S'(388) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(388) -> A(390) -> S'(391) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(391) -> A(392) -> S'(395) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(395) -> A(397) -> S'(398) Reward : \u001b[4m0.769\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(398) -> A(399) -> S'(402) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(402) -> A(403) -> S'(404) Reward : \u001b[4m-1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(404) -> A(406) -> S'(411) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(411) -> A(415) -> S'(416) Reward : \u001b[4m0.588\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  32.12142729759216 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 16 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(22) -> S'(27) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(27) -> A(28) -> S'(383) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(383) -> A(384) -> S'(420) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(420) -> A(423) -> S'(424) Reward : \u001b[4m0.909\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(424) -> A(426) -> S'(427) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -9.09090909090909\n",
      "\u001b[95m[Reward]\u001b[0m S(427) -> A(None) -> S'(None) Reward : \u001b[4m-9.091\u001b[0m\n",
      "########### Running time :  33.2014422416687 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 17 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(22) -> S'(27) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(27) -> A(28) -> S'(383) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(383) -> A(385) -> S'(386) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(386) -> A(428) -> S'(429) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(429) -> A(431) -> S'(433) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(433) -> A(434) -> S'(435) Reward : \u001b[4m-1.667\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(435) -> A(436) -> S'(439) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(439) -> A(442) -> S'(443) Reward : \u001b[4m0.667\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(443) -> A(444) -> S'(446) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(446) -> A(449) -> S'(450) Reward : \u001b[4m0.588\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  34.607441663742065 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 18 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(22) -> S'(27) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(27) -> A(28) -> S'(383) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(383) -> A(385) -> S'(387) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(387) -> A(451) -> S'(452) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(452) -> A(455) -> S'(456) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(456) -> A(459) -> S'(460) Reward : \u001b[4m0.769\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(460) -> A(461) -> S'(466) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(466) -> A(469) -> S'(470) Reward : \u001b[4m0.667\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(470) -> A(472) -> S'(473) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(473) -> A(474) -> S'(476) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  36.69497466087341 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 19 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(22) -> S'(27) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(27) -> A(28) -> S'(383) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(383) -> A(385) -> S'(389) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(389) -> A(477) -> S'(478) Reward : \u001b[4m-2.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m[Reward]\u001b[0m S(478) -> A(480) -> S'(485) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -9.09090909090909\n",
      "\u001b[95m[Reward]\u001b[0m S(485) -> A(None) -> S'(None) Reward : \u001b[4m-9.091\u001b[0m\n",
      "########### Running time :  37.26941227912903 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 20 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(22) -> S'(27) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(27) -> A(28) -> S'(383) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(383) -> A(385) -> S'(388) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(388) -> A(390) -> S'(391) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(391) -> A(393) -> S'(486) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(486) -> A(487) -> S'(488) Reward : \u001b[4m-1.667\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(488) -> A(491) -> S'(493) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(493) -> A(497) -> S'(498) Reward : \u001b[4m0.667\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(498) -> A(500) -> S'(502) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(502) -> A(504) -> S'(505) Reward : \u001b[4m0.588\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  38.3097825050354 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 21 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(22) -> S'(27) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(27) -> A(28) -> S'(383) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(383) -> A(385) -> S'(387) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(387) -> A(451) -> S'(452) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(452) -> A(453) -> S'(506) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(506) -> A(510) -> S'(511) Reward : \u001b[4m0.769\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(511) -> A(513) -> S'(516) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(516) -> A(518) -> S'(520) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(520) -> A(521) -> S'(525) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(525) -> A(527) -> S'(528) Reward : \u001b[4m-1.25\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  39.75077795982361 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 22 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(22) -> S'(27) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(27) -> A(28) -> S'(383) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(383) -> A(385) -> S'(388) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(388) -> A(390) -> S'(391) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(391) -> A(394) -> S'(529) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(529) -> A(533) -> S'(534) Reward : \u001b[4m0.769\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(534) -> A(535) -> S'(542) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(542) -> A(543) -> S'(544) Reward : \u001b[4m0.667\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(544) -> A(545) -> S'(548) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(548) -> A(549) -> S'(550) Reward : \u001b[4m-1.25\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  42.71371555328369 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 23 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(22) -> S'(27) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(27) -> A(28) -> S'(383) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(383) -> A(385) -> S'(386) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(386) -> A(428) -> S'(429) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(429) -> A(430) -> S'(554) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(554) -> A(558) -> S'(560) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(560) -> A(562) -> S'(564) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(564) -> A(565) -> S'(566) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(566) -> A(567) -> S'(570) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(570) -> A(572) -> S'(573) Reward : \u001b[4m0.588\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  44.859137773513794 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 24 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(22) -> S'(27) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(27) -> A(28) -> S'(383) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(383) -> A(385) -> S'(387) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(387) -> A(451) -> S'(452) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(452) -> A(454) -> S'(574) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -9.09090909090909\n",
      "\u001b[95m[Reward]\u001b[0m S(574) -> A(None) -> S'(None) Reward : \u001b[4m-9.091\u001b[0m\n",
      "########### Running time :  44.897071838378906 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 25 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(22) -> S'(27) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(27) -> A(28) -> S'(383) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(383) -> A(385) -> S'(387) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(387) -> A(451) -> S'(452) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(452) -> A(455) -> S'(457) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(457) -> A(576) -> S'(577) Reward : \u001b[4m0.769\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m[Reward]\u001b[0m S(577) -> A(580) -> S'(581) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(581) -> A(584) -> S'(586) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(586) -> A(587) -> S'(589) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(589) -> A(591) -> S'(593) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  46.55020880699158 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 26 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(22) -> S'(27) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(27) -> A(28) -> S'(383) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(383) -> A(385) -> S'(386) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(386) -> A(428) -> S'(429) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(429) -> A(432) -> S'(596) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(596) -> A(598) -> S'(600) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(600) -> A(603) -> S'(604) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(604) -> A(608) -> S'(610) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(610) -> A(613) -> S'(617) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(617) -> A(619) -> S'(620) Reward : \u001b[4m0.588\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  48.26606607437134 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 27 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(22) -> S'(27) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(27) -> A(28) -> S'(383) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(383) -> A(385) -> S'(387) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(387) -> A(451) -> S'(452) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(452) -> A(455) -> S'(456) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(456) -> A(458) -> S'(621) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(621) -> A(623) -> S'(627) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(627) -> A(628) -> S'(630) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(630) -> A(631) -> S'(633) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(633) -> A(634) -> S'(636) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  49.91858100891113 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 28 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(22) -> S'(27) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(27) -> A(28) -> S'(383) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(383) -> A(385) -> S'(387) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(387) -> A(451) -> S'(452) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(452) -> A(455) -> S'(456) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(456) -> A(459) -> S'(460) Reward : \u001b[4m0.769\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(460) -> A(462) -> S'(637) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(637) -> A(638) -> S'(639) Reward : \u001b[4m-1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(639) -> A(641) -> S'(644) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(644) -> A(646) -> S'(647) Reward : \u001b[4m-1.25\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  50.42410588264465 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 29 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(22) -> S'(27) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(27) -> A(28) -> S'(383) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(383) -> A(385) -> S'(388) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(388) -> A(390) -> S'(391) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(391) -> A(393) -> S'(486) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(486) -> A(487) -> S'(488) Reward : \u001b[4m-1.667\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(488) -> A(489) -> S'(648) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(648) -> A(651) -> S'(653) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(653) -> A(655) -> S'(657) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(657) -> A(660) -> S'(661) Reward : \u001b[4m0.588\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  51.805213928222656 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 17\n",
      "\u001b[95m=========== Search iteration : 30 ===========\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(5) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(5) -> A(7) -> S'(8) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(10) -> S'(14) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(14) -> A(15) -> S'(16) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(16) -> A(18) -> S'(19) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(19) -> A(20) -> S'(21) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(21) -> A(22) -> S'(27) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(27) -> A(28) -> S'(383) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(383) -> A(385) -> S'(388) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(388) -> A(390) -> S'(391) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(391) -> A(393) -> S'(486) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(486) -> A(487) -> S'(488) Reward : \u001b[4m-1.667\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(488) -> A(490) -> S'(662) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(662) -> A(666) -> S'(667) Reward : \u001b[4m0.667\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m[Reward]\u001b[0m S(667) -> A(670) -> S'(674) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(674) -> A(676) -> S'(677) Reward : \u001b[4m0.588\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  52.477445125579834 ##############\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for i in range(budgets):\n",
    "# for i in range(10):\n",
    "    print(\n",
    "        f\"\\n[{idx+1}/{len(c_list)}] Benchmark: {rearrangement1.scene_mngr.scene.bench_num}, Algo: {algo}, C: {c}, Seed: {seed}\"\n",
    "    )\n",
    "    mcts.do_planning_rearrange(i)\n",
    "\n",
    "    print(\"########### Running time : \", time.time()- start_time, \"##############\")\n",
    "    final_level_1_values.append(mcts.values_for_level_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f66ba9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 5, 7, 8, 10, 14, 15, 16, 18, 19, 20, 21, 22, 27, 29, 30, 32, 446, 447, 448]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(mcts.get_best_node())\n",
    "\n",
    "\n",
    "print(mcts.get_minimum_cost_node())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16942014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.448773448773449 {0: {'nodes': [0, 1, 73, 238, 239, 241, 243, 246, 247, 250, 251, 254, 256, 258, 260, 261, 262, 265, 266, 267, 268, 269, 272, 273, 274], 'value': 0.5894327894327889}, 1: {'nodes': [0, 1, 73, 238, 239, 241, 244, 375, 376, 378, 380, 382, 383, 386, 387, 390, 391, 392, 1091, 1093, 1094], 'value': 3.448773448773449}}\n",
      "\n",
      "Result 1 :  [0, 1, 73, 238, 239, 241, 244, 375, 376, 378, 380, 382, 383, 386, 387, 390, 391, 392, 1091, 1093, 1094]\n",
      "state num : 21\n"
     ]
    }
   ],
   "source": [
    "max_level_1_value = mcts.get_max_value_level_1()\n",
    "print(max_level_1_value, mcts.history_level_1_dict)\n",
    "\n",
    "########## level 1 ##########\n",
    "if mcts.history_level_1_dict:\n",
    "    j, max_value_nodes = mcts.get_max_value_nodes_level_1()\n",
    "    \n",
    "    print()\n",
    "    print(f\"Result {j} : \", max_value_nodes)\n",
    "    print(\"state num :\", len(max_value_nodes))\n",
    "#     mcts.render_rearr(\"_\", max_value_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "143197e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcts.history_level_2_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c2739e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  1,\n",
       "  29,\n",
       "  136,\n",
       "  137,\n",
       "  139,\n",
       "  211,\n",
       "  214,\n",
       "  215,\n",
       "  218,\n",
       "  219,\n",
       "  223,\n",
       "  224,\n",
       "  225,\n",
       "  231,\n",
       "  236,\n",
       "  237,\n",
       "  238,\n",
       "  243,\n",
       "  247,\n",
       "  248,\n",
       "  251,\n",
       "  255,\n",
       "  258,\n",
       "  259,\n",
       "  260,\n",
       "  267,\n",
       "  268,\n",
       "  269]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcts.infeasible_sub_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93920e69",
   "metadata": {},
   "source": [
    "# Contact graspnet 사용 하는 버전 전용 디버깅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d20d85",
   "metadata": {},
   "source": [
    "## 실패를 했음. 그 와중에 Level 1.5는 다 생성했음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19ae3fe9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes [0, 3, 10, 172, 173, 175, 180, 388, 389, 392, 591, 592, 593, 594, 598, 601, 602, 604, 607, 609, 610]\n",
      "Here doesn't have grasp\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_level_1_value = mcts.get_max_value_level_1()\n",
    "\n",
    "\n",
    "fig, ax = p_utils.init_3d_figure(name=\"Level wise 1\")\n",
    "\n",
    "# nodes = mcts.infeasible_sub_nodes[0]\n",
    "# nodes = mcts.history_level_1_dict[4]['nodes']\n",
    "j, nodes = mcts.get_max_value_nodes_level_1()\n",
    "\n",
    "print(\"nodes\", nodes)\n",
    "i = 0\n",
    "for i in range(len(nodes)//2):\n",
    "    mcts.rearr_action.deepcopy_scene(mcts.tree.nodes[nodes[2*(i)+1]]['state'])\n",
    "    \n",
    "    grasp = mcts.tree.nodes[nodes[2*(i)+1]].get('grasp_poses')\n",
    "    if grasp:\n",
    "        grasp = grasp[0]['grasp']\n",
    "    else:\n",
    "        print(\"Here doesn't have grasp\")\n",
    "        \n",
    "        mcts.rearr_action.scene_mngr.render_objects(ax)\n",
    "        p_utils.plot_basis(ax)\n",
    "        mcts.rearr_action.show()\n",
    "        break\n",
    "    mcts.rearr_action.scene_mngr.set_gripper_pose(grasp)\n",
    "    \n",
    "    gripper_kinematics_info = mcts.rearr_action.scene_mngr.scene.robot.gripper.get_gripper_fk()\n",
    "\n",
    "    gripper_tip_poses = mcts.scene_mngr.scene.robot.gripper.compute_gripper_tip_pose_from_gripper_pose()\n",
    "\n",
    "\n",
    "    mcts.rearr_action.scene_mngr.render_axis(ax, gripper_kinematics_info['leftfinger'])\n",
    "    mcts.rearr_action.scene_mngr.render_axis(ax, gripper_kinematics_info['rightfinger'])\n",
    "    mcts.rearr_action.scene_mngr.render_axis(ax, mcts.scene_mngr.scene.robot.gripper.compute_gripper_tip_pose_from_gripper_pose(gripper_kinematics_info['rightfinger']))\n",
    "    mcts.rearr_action.scene_mngr.render_axis(ax, mcts.scene_mngr.scene.robot.gripper.compute_gripper_tip_pose_from_gripper_pose(gripper_kinematics_info['leftfinger']))\n",
    "\n",
    "    mcts.rearr_action.scene_mngr.render_axis(ax, mcts.rearr_action.scene_mngr.scene.robot.gripper.get_gripper_tcp_pose())\n",
    "    mcts.rearr_action.scene_mngr.render_gripper(ax)\n",
    "\n",
    "    mcts.rearr_action.scene_mngr.render_objects(ax)\n",
    "    p_utils.plot_basis(ax)\n",
    "    mcts.rearr_action.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39ce712",
   "metadata": {},
   "source": [
    "각 node에서 생성한 grasp을 inverse kinematics를 풀어보자 \n",
    "\n",
    "\n",
    "엄청 쉬워보이는 자세인데 왜 IK 실패를 할까"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "edd3cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_curernt_scene(q, pose):\n",
    "    fig, ax = p_utils.init_3d_figure(name=\"Level wise 1\")\n",
    "    \n",
    "    mcts.rearr_action.scene_mngr.set_robot_eef_pose(q)\n",
    "    mcts.rearr_action.scene_mngr.render_axis(ax, mcts.rearr_action.scene_mngr.scene.robot.gripper.get_gripper_pose())\n",
    "    mcts.rearr_action.scene_mngr.render_gripper(ax)\n",
    "    \n",
    "    mcts.rearr_action.scene_mngr.set_gripper_pose(pose)\n",
    "    mcts.rearr_action.scene_mngr.render_axis(ax, mcts.rearr_action.scene_mngr.scene.robot.gripper.get_gripper_pose())\n",
    "    mcts.rearr_action.scene_mngr.render_gripper(ax)\n",
    "\n",
    "    mcts.rearr_action.scene_mngr.render_objects(ax)\n",
    "    p_utils.plot_basis(ax)\n",
    "    mcts.rearr_action.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d792144",
   "metadata": {},
   "source": [
    "여기서 실패가 나는게 말이 안됨.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a50c26b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state node num :  10\n",
      "Current state is came from last action\n",
      "[[ 1.7347235e-18  3.7369016e-01  9.2755359e-01  2.7714780e-01]\n",
      " [-4.5109000e-02  9.2660940e-01 -3.7330979e-01 -1.5398476e-01]\n",
      " [-9.9898207e-01 -4.1841015e-02  1.6856790e-02  8.5422677e-01]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00]]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'pre_release'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m grasp_pose \u001b[38;5;241m=\u001b[39m current_state_node[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrasp\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     20\u001b[0m post_grasp_pose \u001b[38;5;241m=\u001b[39m current_state_node[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost_grasp\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 22\u001b[0m pre_release_pose \u001b[38;5;241m=\u001b[39m \u001b[43mcurrent_state_node\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpre_release\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     23\u001b[0m release_pose \u001b[38;5;241m=\u001b[39m current_state_node[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     24\u001b[0m post_release_pose \u001b[38;5;241m=\u001b[39m current_state_node[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost_release\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pre_release'"
     ]
    }
   ],
   "source": [
    "default_thetas = mcts.rearr_action.scene_mngr.scene.robot.init_qpos\n",
    "\n",
    "for _, i in enumerate(nodes):\n",
    "    if _ < 1:\n",
    "        continue\n",
    "    if _%2 == 1:\n",
    "        continue\n",
    "        \n",
    "    print(\"Current state node num : \",i)\n",
    "    print(\"Current state is came from last action\")\n",
    "    \n",
    "    mcts.rearr_action.deepcopy_scene(mcts.tree.nodes[nodes[2*_-1]]['state'])\n",
    "\n",
    "    last_action_node = mcts.tree.nodes[nodes[2*_+1]]\n",
    "    current_state_node = mcts.tree.nodes[i]\n",
    "    \n",
    "    print(current_state_node['action']['pre_grasp'])\n",
    "    pre_grasp_pose = current_state_node['action']['pre_grasp']\n",
    "    grasp_pose = current_state_node['action']['grasp']\n",
    "    post_grasp_pose = current_state_node['action']['post_grasp']\n",
    "    \n",
    "    pre_release_pose = current_state_node['action']['pre_release']\n",
    "    release_pose = current_state_node['action']['release']\n",
    "    post_release_pose = current_state_node['action']['post_release']\n",
    "    \n",
    "    obj_release_pose = current_state_node['action']['table']\n",
    "    # Set Scene\n",
    "    mcts.rearr_action.scene_mngr.set_robot_eef_pose(default_thetas)\n",
    "    rearr_obj_name = current_state_node['state'].rearr_obj_name\n",
    "    rearr_default_pose = current_state_node['state'].rearr_obj_default_pose\n",
    "    print(\"rearr_obj_name : \", rearr_obj_name)\n",
    "    \n",
    "    mcts.rearr_action.scene_mngr.set_object_pose(rearr_obj_name, rearr_default_pose)\n",
    "\n",
    "    show_curernt_scene(default_thetas ,pre_grasp_pose)\n",
    "    print(\"default 부터 Pre grasp까지 IK 품\")\n",
    "    \n",
    "    goal_q = mcts.rearr_action.scene_mngr.scene.robot.inverse_kin(\n",
    "            default_thetas, pre_grasp_pose, max_iter=100\n",
    "        )\n",
    "    \n",
    "    show_curernt_scene(goal_q, grasp_pose)\n",
    "    print(\"pre_grasp 부터 grasp까지 IK 품\")\n",
    "    goal_q = mcts.rearr_action.scene_mngr.scene.robot.inverse_kin(\n",
    "        goal_q, grasp_pose, max_iter=100\n",
    "    )\n",
    "    \n",
    "    show_curernt_scene(goal_q, post_grasp_pose)\n",
    "    print(\"grasp 부터 post_grasp까지 IK 품\")\n",
    "    goal_q = mcts.rearr_action.scene_mngr.scene.robot.inverse_kin(\n",
    "        goal_q, post_grasp_pose, max_iter=100\n",
    "    )\n",
    "    \n",
    "    mcts.rearr_action.scene_mngr.set_robot_eef_pose(default_thetas)\n",
    "\n",
    "    mcts.rearr_action.scene_mngr.set_object_pose(rearr_obj_name, obj_release_pose)\n",
    "\n",
    "    show_curernt_scene(default_thetas, post_release_pose)\n",
    "    print(\"default 부터 post_release까지 IK 품\")\n",
    "    goal_q = mcts.rearr_action.scene_mngr.scene.robot.inverse_kin(\n",
    "        default_thetas, pre_release_pose, max_iter=100\n",
    "    )\n",
    "    \n",
    "    show_curernt_scene(goal_q, release_pose)\n",
    "    print(\"release 부터 post_release까지 IK 품\")\n",
    "    goal_q = mcts.rearr_action.scene_mngr.scene.robot.inverse_kin(\n",
    "        goal_q, release_pose, max_iter=100\n",
    "    )\n",
    "    \n",
    "    show_curernt_scene(goal_q, post_release_pose)\n",
    "    print(\"post_release 부터 post_release까지 IK 품\")\n",
    "    goal_q = mcts.rearr_action.scene_mngr.scene.robot.inverse_kin(\n",
    "        goal_q, release_pose, max_iter=100\n",
    "    )\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5060b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## level 1 ##########\n",
    "if mcts.history_level_2_dict:\n",
    "    j, max_value_nodes = mcts.get_max_value_nodes_level_1()\n",
    "    print(f\"Result {j} : \", max_value_nodes)\n",
    "    print(\"state num :\", len(max_value_nodes))\n",
    "    mcts.render_rearr(\"_\", max_value_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0740b4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a47457f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'release': array([[-0.035319  ,  0.49304995, -0.8692838 ,  0.6695346 ],\n",
       "        [ 0.02806048, -0.8689943 , -0.49402586,  0.3249112 ],\n",
       "        [-0.9989821 , -0.04184102,  0.01685679,  0.85591245],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]],\n",
       "       dtype=float32),\n",
       " 'pre_release': array([[-0.035319  ,  0.49304995, -0.8692838 ,  0.6695346 ],\n",
       "        [ 0.02806048, -0.8689943 , -0.49402586,  0.3249112 ],\n",
       "        [-0.9989821 , -0.04184102,  0.01685679,  0.90591246],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]],\n",
       "       dtype=float32),\n",
       " 'post_release': array([[-0.035319  ,  0.49304995, -0.8692838 ,  0.7129988 ],\n",
       "        [ 0.02806048, -0.8689943 , -0.49402586,  0.3496125 ],\n",
       "        [-0.9989821 , -0.04184102,  0.01685679,  0.85506964],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcts.tree.nodes[172]['action']['rearr_poses'][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6da63",
   "metadata": {},
   "source": [
    "# Pick action 사용하는 버전 전용 디버깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9acca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes [0, 1, 29, 136, 137, 139, 211, 214, 215, 218, 219, 223, 224, 225, 231, 236, 237, 238, 243, 247, 248, 251, 255, 258, 259, 260, 267, 268, 269]\n",
      "1\n",
      "136\n",
      "139\n",
      "214\n",
      "218\n",
      "223\n",
      "225\n",
      "236\n",
      "238\n",
      "247\n",
      "251\n",
      "258\n",
      "260\n",
      "268\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_level_1_value = mcts.get_max_value_level_1()\n",
    "\n",
    "fig, ax = p_utils.init_3d_figure(name=\"Level wise 1\")\n",
    "\n",
    "j, nodes = mcts.get_max_value_nodes_level_1()\n",
    "\n",
    "print(\"nodes\", nodes)\n",
    "i = 0\n",
    "for i in range(len(nodes)//2):\n",
    "    print(nodes[2*(i)+1])\n",
    "    mcts.rearr_action.deepcopy_scene(mcts.tree.nodes[nodes[2*(i)+1]]['state'])\n",
    "    \n",
    "    action_type = mcts.tree.nodes[nodes[2*(i)+1]].get('action').get('type')\n",
    "    if action_type == 'pick':\n",
    "        grasp = mcts.tree.nodes[nodes[2*(i)+1]].get('action').get('grasp_poses')\n",
    "        if grasp:\n",
    "            grasp = grasp[0]['grasp']\n",
    "        else:\n",
    "            print(\"Here doesn't have grasp\")\n",
    "            mcts.rearr_action.scene_mngr.render_objects(ax)\n",
    "            p_utils.plot_basis(ax)\n",
    "            mcts.rearr_action.show()\n",
    "            break\n",
    "    if action_type == 'rearr':\n",
    "        grasp = mcts.tree.nodes[nodes[2*(i)+1]].get('action').get('rearr_poses')[0]\n",
    "        if grasp:\n",
    "            grasp = grasp[0].get('release')\n",
    "        else:\n",
    "            print(\"Here doesn't have grasp\")\n",
    "\n",
    "            mcts.rearr_action.scene_mngr.render_objects(ax)\n",
    "            p_utils.plot_basis(ax)\n",
    "            mcts.rearr_action.show()\n",
    "            break\n",
    "    mcts.rearr_action.scene_mngr.set_gripper_pose(grasp)\n",
    "    \n",
    "    gripper_kinematics_info = mcts.rearr_action.scene_mngr.scene.robot.gripper.get_gripper_fk()\n",
    "\n",
    "    gripper_tip_poses = mcts.scene_mngr.scene.robot.gripper.compute_gripper_tip_pose_from_gripper_pose()\n",
    "\n",
    "\n",
    "    mcts.rearr_action.scene_mngr.render_axis(ax, gripper_kinematics_info['leftfinger'])\n",
    "    mcts.rearr_action.scene_mngr.render_axis(ax, gripper_kinematics_info['rightfinger'])\n",
    "    mcts.rearr_action.scene_mngr.render_axis(ax, mcts.scene_mngr.scene.robot.gripper.compute_gripper_tip_pose_from_gripper_pose(gripper_kinematics_info['rightfinger']))\n",
    "    mcts.rearr_action.scene_mngr.render_axis(ax, mcts.scene_mngr.scene.robot.gripper.compute_gripper_tip_pose_from_gripper_pose(gripper_kinematics_info['leftfinger']))\n",
    "\n",
    "    mcts.rearr_action.scene_mngr.render_axis(ax, mcts.rearr_action.scene_mngr.scene.robot.gripper.get_gripper_tcp_pose())\n",
    "    mcts.rearr_action.scene_mngr.render_gripper(ax)\n",
    "\n",
    "    mcts.rearr_action.scene_mngr.render_objects(ax)\n",
    "    p_utils.plot_basis(ax)\n",
    "    mcts.rearr_action.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "02b58c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': 9,\n",
       " 'state': <pytamp.scene.scene.Scene at 0x7fda003d4670>,\n",
       " 'action': {'type': 'pick',\n",
       "  'pick_obj_name': 'can0',\n",
       "  'grasp_poses': [{'grasp': array([[ 1.73472348e-18,  5.33759997e-01,  8.45636013e-01,\n",
       "             5.02205085e-01],\n",
       "           [ 3.42664046e-02,  8.45139400e-01, -5.33446538e-01,\n",
       "             3.29901541e-01],\n",
       "           [-9.99412734e-01,  2.89769058e-02, -1.82900360e-02,\n",
       "             8.72814208e-01],\n",
       "           [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "             1.00000000e+00]]),\n",
       "    'pre_grasp': array([[ 1.7347235e-18,  5.3376001e-01,  8.4563601e-01,  4.1764149e-01],\n",
       "           [ 3.4266405e-02,  8.4513938e-01, -5.3344655e-01,  3.8324618e-01],\n",
       "           [-9.9941272e-01,  2.8976906e-02, -1.8290035e-02,  8.7464321e-01],\n",
       "           [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "          dtype=float32),\n",
       "    'post_grasp': array([[ 1.7347235e-18,  5.3376001e-01,  8.4563601e-01,  5.0220507e-01],\n",
       "           [ 3.4266405e-02,  8.4513938e-01, -5.3344655e-01,  3.2990155e-01],\n",
       "           [-9.9941272e-01,  2.8976906e-02, -1.8290035e-02,  9.7281420e-01],\n",
       "           [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "          dtype=float32)},\n",
       "   {'grasp': array([[-8.45636013e-01,  5.33759997e-01,  5.17802718e-17,\n",
       "             5.84231778e-01],\n",
       "           [ 5.33446538e-01,  8.45139400e-01,  3.42664046e-02,\n",
       "             2.74833385e-01],\n",
       "           [ 1.82900360e-02,  2.89769058e-02, -9.99412734e-01,\n",
       "             9.67983110e-01],\n",
       "           [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "             1.00000000e+00]]),\n",
       "    'pre_grasp': array([[-8.4563601e-01,  5.3376001e-01,  5.1780272e-17,  5.8423179e-01],\n",
       "           [ 5.3344655e-01,  8.4513938e-01,  3.4266405e-02,  2.7140674e-01],\n",
       "           [ 1.8290035e-02,  2.8976906e-02, -9.9941272e-01,  1.0679244e+00],\n",
       "           [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "          dtype=float32),\n",
       "    'post_grasp': array([[-8.4563601e-01,  5.3376001e-01,  5.1780272e-17,  5.8423179e-01],\n",
       "           [ 5.3344655e-01,  8.4513938e-01,  3.4266405e-02,  2.7483338e-01],\n",
       "           [ 1.8290035e-02,  2.8976906e-02, -9.9941272e-01,  1.0679832e+00],\n",
       "           [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "          dtype=float32)},\n",
       "   {'grasp': array([[-1.04083409e-16,  5.33759997e-01, -8.45636013e-01,\n",
       "             6.66258471e-01],\n",
       "           [-3.42664046e-02,  8.45139400e-01,  5.33446538e-01,\n",
       "             2.26412912e-01],\n",
       "           [ 9.99412734e-01,  2.89769058e-02,  1.82900360e-02,\n",
       "             8.69265941e-01],\n",
       "           [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "             1.00000000e+00]]),\n",
       "    'pre_grasp': array([[-1.0408341e-16,  5.3376001e-01, -8.4563601e-01,  7.5082207e-01],\n",
       "           [-3.4266405e-02,  8.4513938e-01,  5.3344655e-01,  1.7306826e-01],\n",
       "           [ 9.9941272e-01,  2.8976906e-02,  1.8290035e-02,  8.6743695e-01],\n",
       "           [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "          dtype=float32),\n",
       "    'post_grasp': array([[-1.0408341e-16,  5.3376001e-01, -8.4563601e-01,  6.6625845e-01],\n",
       "           [-3.4266405e-02,  8.4513938e-01,  5.3344655e-01,  2.2641291e-01],\n",
       "           [ 9.9941272e-01,  2.8976906e-02,  1.8290035e-02,  9.6926594e-01],\n",
       "           [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "          dtype=float32)}]},\n",
       " 'value': 5.8090909090909095,\n",
       " 'value_history': [5.8090909090909095,\n",
       "  -6.778431372549019,\n",
       "  5.8090909090909095,\n",
       "  5.8090909090909095,\n",
       "  -8.795238095238096,\n",
       "  5.8090909090909095,\n",
       "  5.8090909090909095,\n",
       "  5.8090909090909095,\n",
       "  5.8090909090909095,\n",
       "  5.8090909090909095,\n",
       "  5.8090909090909095,\n",
       "  5.8090909090909095,\n",
       "  5.8090909090909095],\n",
       " 'visit': 13,\n",
       " 'number': 604,\n",
       " 'type': 'action',\n",
       " 'joints': [],\n",
       " 'level1': True,\n",
       " 'level2': False,\n",
       " 'level1_5': False,\n",
       " 'success': False,\n",
       " 'cost': 0,\n",
       " 'test': ()}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcts.tree.nodes[604]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb0a9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82697d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd448af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a2860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45c06ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8bfa27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b89d6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d7921d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3fadd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value_nodes = mcts.get_minimum_cost_node()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a41158",
   "metadata": {},
   "source": [
    "## Save path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46552e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_level_1_values = []\n",
    "final_level_2_values = []\n",
    "final_optimal_nodes = []\n",
    "final_pnp_all_joint_paths = []\n",
    "final_pick_all_objects = []\n",
    "final_place_all_object_poses = []\n",
    "if mcts.level_wise_2_success:\n",
    "    (\n",
    "        pnp_all_joint_paths,\n",
    "        pick_all_objects,\n",
    "        place_all_object_poses,\n",
    "    ) = mcts.get_all_joint_path(max_value_nodes)\n",
    "    final_pnp_all_joint_paths.append(pnp_all_joint_paths)\n",
    "    final_pick_all_objects.append(pick_all_objects)\n",
    "    final_place_all_object_poses.append(place_all_object_poses)\n",
    "    final_optimal_nodes.append(mcts.optimal_nodes)\n",
    "else:\n",
    "    final_pnp_all_joint_paths.append([])\n",
    "    final_pick_all_objects.append([])\n",
    "    final_place_all_object_poses.append([])\n",
    "    final_optimal_nodes.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3545a5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 1.5 1739\n"
     ]
    }
   ],
   "source": [
    "for i in max_value_nodes:\n",
    "    if not mcts.tree.nodes[i]['level1_5']:\n",
    "        print(\"Error 1.5\", i)\n",
    "for i in max_value_nodes:\n",
    "    if not mcts.tree.nodes[i]['level2']:\n",
    "        print(\"Error 2\", i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce950ec1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 scene\n",
      "100 scene\n",
      "200 scene\n",
      "300 scene\n",
      "400 scene\n",
      "500 scene\n",
      "600 scene\n",
      "700 scene\n",
      "800 scene\n",
      "900 scene\n",
      "1000 scene\n",
      "Animation Finished..\n",
      "PWD :  /home/juju/pytamp/examples/doosan/action/rearrangement1/movie_dir\n",
      "Save finished..\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pykin.utils.kin_utils import apply_robot_to_scene\n",
    "\n",
    "mcts.rearr_action.scene_mngr.render.render_objects(mcts.tree.nodes[0]['state'].objs)\n",
    "# pick.scene_mngr.render.trimesh_scene = apply_robot_to_scene(\n",
    "#         trimesh_scene=pick.scene_mngr.render.trimesh_scene, \n",
    "#         robot=pick.scene_mngr.scene.robot,\n",
    "#         geom=\"visual\"\n",
    "#             )\n",
    "# pick.scene_mngr.render.set_camera_view()\n",
    "\n",
    "mcts.rearr_action.simulate_path(\n",
    "    final_pnp_all_joint_paths[0],\n",
    "    final_pick_all_objects[0],\n",
    "    final_place_all_object_poses[0],\n",
    "    is_save=True,\n",
    "#     video_name=\"pick_rearrangement1_only_current_scene\",\n",
    "    video_name=\"pick_rearrangement1_consider_only_current_scene_minimum_cost_nodes\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4f9fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f754388a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': 1,\n",
       " 'state': <pytamp.scene.scene.Scene at 0x7fda17004a00>,\n",
       " 'action': {'type': 'pick',\n",
       "  'pick_obj_name': 'can0',\n",
       "  'grasp_poses': [{'grasp': array([[ 0.        ,  0.59427848,  0.80425934,  0.38289493],\n",
       "           [ 0.00525198,  0.80424825, -0.59427028, -0.17083556],\n",
       "           [-0.99998621,  0.00422396, -0.00312114,  0.86611772],\n",
       "           [ 0.        ,  0.        ,  0.        ,  1.        ]]),\n",
       "    'pre_grasp': array([[ 0.        ,  0.59427845,  0.80425936,  0.30246902],\n",
       "           [ 0.00525198,  0.8042483 , -0.5942703 , -0.11140853],\n",
       "           [-0.99998623,  0.00422396, -0.00312114,  0.8664298 ],\n",
       "           [ 0.        ,  0.        ,  0.        ,  1.        ]],\n",
       "          dtype=float32),\n",
       "    'post_grasp': array([[ 0.        ,  0.59427845,  0.80425936,  0.38289493],\n",
       "           [ 0.00525198,  0.8042483 , -0.5942703 , -0.17083555],\n",
       "           [-0.99998623,  0.00422396, -0.00312114,  0.96611774],\n",
       "           [ 0.        ,  0.        ,  0.        ,  1.        ]],\n",
       "          dtype=float32)},\n",
       "   {'grasp': array([[-8.04259342e-01,  5.94278480e-01,  1.06188044e-14,\n",
       "             4.60908091e-01],\n",
       "           [ 5.94270284e-01,  8.04248249e-01,  5.25198430e-03,\n",
       "            -2.28989218e-01],\n",
       "           [ 3.12114125e-03,  4.22395744e-03, -9.99986208e-01,\n",
       "             9.62813633e-01],\n",
       "           [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "             1.00000000e+00]]),\n",
       "    'pre_grasp': array([[-8.0425936e-01,  5.9427845e-01,  1.0618804e-14,  4.6090809e-01],\n",
       "           [ 5.9427029e-01,  8.0424827e-01,  5.2519841e-03, -2.2951442e-01],\n",
       "           [ 3.1211413e-03,  4.2239577e-03, -9.9998623e-01,  1.0628122e+00],\n",
       "           [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "          dtype=float32),\n",
       "    'post_grasp': array([[-8.0425936e-01,  5.9427845e-01,  1.0618804e-14,  4.6090809e-01],\n",
       "           [ 5.9427029e-01,  8.0424827e-01,  5.2519841e-03, -2.2898921e-01],\n",
       "           [ 3.1211413e-03,  4.2239577e-03, -9.9998623e-01,  1.0628136e+00],\n",
       "           [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "          dtype=float32)},\n",
       "   {'grasp': array([[ 8.67361738e-19,  6.93705492e-02,  9.97590962e-01,\n",
       "             3.64132064e-01],\n",
       "           [ 6.12110789e-02,  9.95720323e-01, -6.92404686e-02,\n",
       "            -2.20765634e-01],\n",
       "           [-9.98124844e-01,  6.10636191e-02, -4.24624616e-03,\n",
       "             8.71653369e-01],\n",
       "           [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "             1.00000000e+00]]),\n",
       "    'pre_grasp': array([[ 8.6736174e-19,  6.9370553e-02,  9.9759096e-01,  2.6437297e-01],\n",
       "           [ 6.1211079e-02,  9.9572033e-01, -6.9240466e-02, -2.1384159e-01],\n",
       "           [-9.9812484e-01,  6.1063617e-02, -4.2462461e-03,  8.7207800e-01],\n",
       "           [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "          dtype=float32),\n",
       "    'post_grasp': array([[ 8.6736174e-19,  6.9370553e-02,  9.9759096e-01,  3.6413208e-01],\n",
       "           [ 6.1211079e-02,  9.9572033e-01, -6.9240466e-02, -2.2076564e-01],\n",
       "           [-9.9812484e-01,  6.1063617e-02, -4.2462461e-03,  9.7165334e-01],\n",
       "           [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "          dtype=float32)},\n",
       "   {'grasp': array([[-9.97590962e-01,  6.93705492e-02,  2.87805025e-16,\n",
       "             4.60898388e-01],\n",
       "           [ 6.92404686e-02,  9.95720323e-01,  6.12110789e-02,\n",
       "            -2.33419435e-01],\n",
       "           [ 4.24624616e-03,  6.10636191e-02, -9.98124844e-01,\n",
       "             9.68059593e-01],\n",
       "           [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "             1.00000000e+00]]),\n",
       "    'pre_grasp': array([[-9.9759096e-01,  6.9370553e-02,  2.8780501e-16,  4.6089840e-01],\n",
       "           [ 6.9240466e-02,  9.9572033e-01,  6.1211079e-02, -2.3954055e-01],\n",
       "           [ 4.2462461e-03,  6.1063617e-02, -9.9812484e-01,  1.0678720e+00],\n",
       "           [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "          dtype=float32),\n",
       "    'post_grasp': array([[-9.9759096e-01,  6.9370553e-02,  2.8780501e-16,  4.6089840e-01],\n",
       "           [ 6.9240466e-02,  9.9572033e-01,  6.1211079e-02, -2.3341943e-01],\n",
       "           [ 4.2462461e-03,  6.1063617e-02, -9.9812484e-01,  1.0680596e+00],\n",
       "           [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "          dtype=float32)},\n",
       "   {'grasp': array([[ 8.32667268e-17,  7.83753656e-01, -6.21071821e-01,\n",
       "             5.19137509e-01],\n",
       "           [ 1.52720020e-01, -6.13786335e-01, -7.74559830e-01,\n",
       "            -1.52742894e-01],\n",
       "           [-9.88269495e-01, -9.48501012e-02, -1.19694874e-01,\n",
       "             8.51534137e-01],\n",
       "           [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "             1.00000000e+00]]),\n",
       "    'pre_grasp': array([[ 8.3266727e-17,  7.8375363e-01, -6.2107182e-01,  5.8124471e-01],\n",
       "           [ 1.5272002e-01, -6.1378634e-01, -7.7455986e-01, -7.5286910e-02],\n",
       "           [-9.8826951e-01, -9.4850101e-02, -1.1969487e-01,  8.6350363e-01],\n",
       "           [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "          dtype=float32),\n",
       "    'post_grasp': array([[ 8.3266727e-17,  7.8375363e-01, -6.2107182e-01,  5.1913750e-01],\n",
       "           [ 1.5272002e-01, -6.1378634e-01, -7.7455986e-01, -1.5274289e-01],\n",
       "           [-9.8826951e-01, -9.4850101e-02, -1.1969487e-01,  9.5153415e-01],\n",
       "           [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "          dtype=float32)},\n",
       "   {'grasp': array([[ 1.73472348e-18,  3.73690170e-01,  9.27553587e-01,\n",
       "             3.69903150e-01],\n",
       "           [-4.51089992e-02,  9.26609403e-01, -3.73309780e-01,\n",
       "            -1.91315731e-01],\n",
       "           [-9.98982071e-01, -4.18410140e-02,  1.68567896e-02,\n",
       "             8.55912436e-01],\n",
       "           [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "             1.00000000e+00]]),\n",
       "    'pre_grasp': array([[ 1.7347235e-18,  3.7369016e-01,  9.2755359e-01,  2.7714780e-01],\n",
       "           [-4.5109000e-02,  9.2660940e-01, -3.7330979e-01, -1.5398476e-01],\n",
       "           [-9.9898207e-01, -4.1841015e-02,  1.6856790e-02,  8.5422677e-01],\n",
       "           [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "          dtype=float32),\n",
       "    'post_grasp': array([[ 1.7347235e-18,  3.7369016e-01,  9.2755359e-01,  3.6990315e-01],\n",
       "           [-4.5109000e-02,  9.2660940e-01, -3.7330979e-01, -1.9131573e-01],\n",
       "           [-9.9898207e-01, -4.1841015e-02,  1.6856790e-02,  9.5591241e-01],\n",
       "           [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "          dtype=float32)}]},\n",
       " 'value': 4.548773448773449,\n",
       " 'value_history': [-8.866666666666667,\n",
       "  -20.0,\n",
       "  -8.06013986013986,\n",
       "  -8.399999999999999,\n",
       "  -7.0285714285714285,\n",
       "  -3.4825396825396835,\n",
       "  -13.314102564102562,\n",
       "  -8.866666666666667,\n",
       "  -13.499999999999996,\n",
       "  -7.707070707070704,\n",
       "  -7.9090909090909065,\n",
       "  -10.876984126984127,\n",
       "  -8.399999999999999,\n",
       "  -8.399999999999999,\n",
       "  -8.02222222222222,\n",
       "  -9.52222222222222,\n",
       "  -8.707070707070704,\n",
       "  -5.4,\n",
       "  4.548773448773449,\n",
       "  -10.149859943977589,\n",
       "  -12.919480519480517,\n",
       "  -8.547295841413488,\n",
       "  -8.885531135531135,\n",
       "  -9.467320261437905,\n",
       "  -2.0472958414134896,\n",
       "  -10.969230769230768,\n",
       "  -3.4825396825396835,\n",
       "  -3.4825396825396835,\n",
       "  -13.230769230769228,\n",
       "  -8.852991452991452,\n",
       "  -8.038748832866478,\n",
       "  -3.4825396825396835,\n",
       "  -12.804761904761904,\n",
       "  -5.593650793650795,\n",
       "  -8.389610389610388,\n",
       "  4.548773448773449,\n",
       "  -3.4825396825396835,\n",
       "  4.548773448773449,\n",
       "  -6.482539682539683,\n",
       "  -5.278499278499279,\n",
       "  -10.055555555555554,\n",
       "  -8.54065934065934,\n",
       "  -9.457142857142856,\n",
       "  -9.210317460317459,\n",
       "  -9.96410256410256,\n",
       "  -3.4825396825396835,\n",
       "  4.548773448773449,\n",
       "  -10.943900543900542,\n",
       "  4.548773448773449,\n",
       "  -5.4,\n",
       "  -8.54065934065934,\n",
       "  -5.593650793650795,\n",
       "  4.548773448773449,\n",
       "  4.548773448773449,\n",
       "  -5.593650793650795,\n",
       "  4.548773448773449,\n",
       "  4.548773448773449,\n",
       "  -3.4825396825396835,\n",
       "  -8.865445665445664,\n",
       "  -8.80065359477124,\n",
       "  -4.028571428571429,\n",
       "  -5.4,\n",
       "  -8.389610389610388,\n",
       "  -3.4825396825396835,\n",
       "  -9.467320261437905,\n",
       "  -8.54065934065934,\n",
       "  -11.07142857142857,\n",
       "  -3.4825396825396835,\n",
       "  -5.593650793650795,\n",
       "  -3.4825396825396835,\n",
       "  -4.028571428571429,\n",
       "  -5.593650793650795,\n",
       "  4.548773448773449,\n",
       "  -10.309890109890109,\n",
       "  -5.278499278499279,\n",
       "  4.548773448773449,\n",
       "  -6.4571428571428555,\n",
       "  -3.4825396825396835,\n",
       "  -6.4571428571428555,\n",
       "  -14.738461538461536,\n",
       "  4.548773448773449,\n",
       "  -7.865445665445664,\n",
       "  -5.4,\n",
       "  -8.399999999999999,\n",
       "  -5.4,\n",
       "  -3.4825396825396835,\n",
       "  -5.4],\n",
       " 'visit': 87,\n",
       " 'number': 3,\n",
       " 'type': 'action',\n",
       " 'joints': [],\n",
       " 'level1': True,\n",
       " 'level2': True,\n",
       " 'level1_5': False,\n",
       " 'success': False,\n",
       " 'cost': 0,\n",
       " 'test': ()}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcts.tree.nodes[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25a0151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [0, 3, 10, 172, 173, 175, 180, 388, 389, 392, 591, 592, 593, 594, 598, 601, 602, 604, 607, 609, 610]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d596933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i in nodes:\n",
    "    print(mcts.tree.nodes[i][\"level2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ada486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c684115a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2066cf89",
   "metadata": {},
   "source": [
    "\n",
    "# Level 1에서 무조건 좋아질 조합 찾고 Path 계산해도 Cost가 무조건 좋아져야하는데 안됨. \n",
    "\n",
    "분석  : 이미 성공한 list에서 cost 계산\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "856fad99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 82, 84, 88, 94, 1254, 1256, 1473, 1476, 1478]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcts.get_best_node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7be3aea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 205, 206, 706, 709, 1608, 1610, 1614, 1618, 1619]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_value_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dc479c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minimum_cost_node():\n",
    "    min_cost = 100\n",
    "    min_cost_nodes = []\n",
    "    for i, n in mcts.history_level_2_dict.items():\n",
    "        cost = 0\n",
    "        print(i,n)\n",
    "        for n_num in n['nodes']:\n",
    "            cost += mcts.tree.nodes[n_num].get('cost')\n",
    "        if min_cost > cost:\n",
    "            min_cost = cost\n",
    "            min_cost_nodes = n['nodes']\n",
    "    return min_cost_nodes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a8d059a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'nodes': [0, 7, 446, 449, 644, 645, 650, 654, 656, 661, 662, 664, 668, 669, 674, 678, 679, 682, 684], 'value': 8.053283}\n",
      "1 {'nodes': [0, 7, 446, 449, 644, 647, 802, 804, 808, 812, 814, 818, 819, 822, 823, 825, 828, 832, 833, 837, 838], 'value': 8.525124}\n",
      "2 {'nodes': [0, 7, 446, 449, 644, 648, 839, 843, 845, 846, 849], 'value': 14.897667}\n",
      "3 {'nodes': [0, 7, 446, 449, 644, 648, 839, 841, 1193, 1194, 1196], 'value': 14.938767}\n",
      "4 {'nodes': [0, 7, 446, 450, 452, 454, 1487, 1490, 1492], 'value': 14.938767}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 7, 446, 450, 452, 454, 1487, 1490, 1492]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_minimum_cost_node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdef708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b829255b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55c939b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b64ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50f45ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contact_graspnet",
   "language": "python",
   "name": "contact_graspnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
