{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9182d1bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--budgets T] [--max_depth H] [--seed i]\n",
      "                             [--algo alg] [--debug_mode DEBUG_MODE]\n",
      "                             [--disk_number N]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/juju/.local/share/jupyter/runtime/kernel-b8409916-58d0-4cb9-8845-d7671847443f.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hanoi_disk_0\n",
      "hanoi_disk_1\n",
      "hanoi_disk_2\n",
      "*********************** \u001b[92mLogical States\u001b[0m ***********************\n",
      "OrderedDict([('peg_1',\n",
      "              {'hung': [\u001b[95mObject\u001b[0m(name=hanoi_disk_0, pos=[0.69991433 0.3        0.75529998]),\n",
      "                        \u001b[95mObject\u001b[0m(name=hanoi_disk_1, pos=[0.69991433 0.3        0.79529998]),\n",
      "                        \u001b[95mObject\u001b[0m(name=hanoi_disk_2, pos=[0.69991433 0.3        0.83529997])],\n",
      "               'on': \u001b[95mObject\u001b[0m(name=table, pos=[ 1.   -0.6  -0.03]),\n",
      "               'static': True}),\n",
      "             ('peg_2',\n",
      "              {'on': \u001b[95mObject\u001b[0m(name=table, pos=[ 1.   -0.6  -0.03]),\n",
      "               'static': True}),\n",
      "             ('peg_3',\n",
      "              {'on': \u001b[95mObject\u001b[0m(name=table, pos=[ 1.   -0.6  -0.03]),\n",
      "               'static': True}),\n",
      "             ('hanoi_disk_0',\n",
      "              {'hang': \u001b[95mObject\u001b[0m(name=peg_1, pos=[0.7        0.3        0.83529998]),\n",
      "               'on': \u001b[95mObject\u001b[0m(name=table, pos=[ 1.   -0.6  -0.03]),\n",
      "               'support': [\u001b[95mObject\u001b[0m(name=hanoi_disk_1, pos=[0.69991433 0.3        0.79529998])]}),\n",
      "             ('hanoi_disk_1',\n",
      "              {'hang': \u001b[95mObject\u001b[0m(name=peg_1, pos=[0.7        0.3        0.83529998]),\n",
      "               'on': \u001b[95mObject\u001b[0m(name=hanoi_disk_0, pos=[0.69991433 0.3        0.75529998]),\n",
      "               'support': [\u001b[95mObject\u001b[0m(name=hanoi_disk_2, pos=[0.69991433 0.3        0.83529997])]}),\n",
      "             ('hanoi_disk_2',\n",
      "              {'hang': \u001b[95mObject\u001b[0m(name=peg_1, pos=[0.7        0.3        0.83529998]),\n",
      "               'on': \u001b[95mObject\u001b[0m(name=hanoi_disk_1, pos=[0.69991433 0.3        0.79529998])}),\n",
      "             ('table',\n",
      "              {'holding': None,\n",
      "               'static': True,\n",
      "               'support': [\u001b[95mObject\u001b[0m(name=peg_1, pos=[0.7        0.3        0.83529998]),\n",
      "                           \u001b[95mObject\u001b[0m(name=peg_2, pos=[0.7        0.         0.83529998]),\n",
      "                           \u001b[95mObject\u001b[0m(name=peg_3, pos=[ 0.7        -0.3         0.83529998]),\n",
      "                           \u001b[95mObject\u001b[0m(name=hanoi_disk_0, pos=[0.69991433 0.3        0.75529998])]}),\n",
      "             ('robotiq140_gripper', {'holding': None})])\n",
      "***************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from pykin.utils import plot_utils as p_utils\n",
    "from pytamp.benchmark import Benchmark4\n",
    "from pytamp.search.mcts import MCTS\n",
    "\n",
    "\n",
    "# #? python3 benchmark4_test.py --budgets 1000 --max_depth 20 --seed 3 --algo bai_ucb\n",
    "parser = argparse.ArgumentParser(description=\"Test Benchmark 4.\")\n",
    "parser.add_argument(\"--budgets\", metavar=\"T\", type=int, default=100, help=\"Horizon\")\n",
    "parser.add_argument(\"--max_depth\", metavar=\"H\", type=int, default=20, help=\"Max depth\")\n",
    "parser.add_argument(\"--seed\", metavar=\"i\", type=int, default=1, help=\"A random seed\")\n",
    "parser.add_argument(\n",
    "    \"--algo\",\n",
    "    metavar=\"alg\",\n",
    "    type=str,\n",
    "    default=\"bai_perturb\",\n",
    "    choices=[\"bai_perturb\", \"bai_ucb\", \"uct\", \"random\", \"greedy\"],\n",
    "    help=\"Choose one (bai_perturb, bai_ucb, uct)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--debug_mode\", default=False, type=lambda x: (str(x).lower() == \"true\"), help=\"Debug mode\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--disk_number\", metavar=\"N\", type=int, default=3, help=\"Disk Number(5 or less.)\"\n",
    ")\n",
    "try:\n",
    "    args = parser.parse_args() #call from command line\n",
    "except:\n",
    "    args = parser.parse_args(args=[]) #call from notebook\n",
    "debug_mode = args.debug_mode\n",
    "budgets = args.budgets\n",
    "max_depth = args.max_depth\n",
    "algo = args.algo\n",
    "seed = args.seed\n",
    "number = args.disk_number\n",
    "np.random.seed(seed)\n",
    "\n",
    "benchmark4 = Benchmark4(robot_name=\"doosan\", geom=\"collision\", is_pyplot=True, disk_num=number)\n",
    "final_level_1_values = []\n",
    "final_level_2_values = []\n",
    "final_optimal_nodes = []\n",
    "final_pnp_all_joint_paths = []\n",
    "final_pick_all_objects = []\n",
    "final_place_all_object_poses = []\n",
    "# final_optimal_trees = []\n",
    "c_list = 10 ** np.linspace(-2, 2.0, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57b8c7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m=========== Search iteration : 1 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 2 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 3 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 4 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 5 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 6 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 7 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 8 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 9 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 10 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 11 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 12 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 13 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 14 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 15 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 16 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 17 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 18 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 19 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 20 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 21 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 22 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 23 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 24 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 25 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 26 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 27 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 28 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 29 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 30 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 31 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 32 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 33 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 34 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 35 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 36 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 37 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 38 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 39 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 40 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 41 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 42 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 43 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 44 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 45 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 46 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 47 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 48 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 49 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 50 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 51 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 52 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 53 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 54 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 55 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 56 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 57 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 58 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 59 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 60 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 61 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 62 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 63 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 64 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 65 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 66 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 67 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 68 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 69 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 70 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 71 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 72 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 73 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 74 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 75 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 76 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 77 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 78 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 79 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 80 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 81 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 82 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 83 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 84 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 85 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 86 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 87 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 88 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 89 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 90 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 91 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 92 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 93 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 94 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 95 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 96 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 97 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 98 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 99 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 100 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 101 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 102 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 103 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 104 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 105 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 106 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 107 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 108 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 109 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 110 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 111 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 112 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 113 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 114 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 115 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 116 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 117 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 118 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 119 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 120 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 121 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 122 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 123 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 124 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 125 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 126 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 127 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 128 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 129 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 130 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 131 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 132 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 133 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 134 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 135 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 136 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 137 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 138 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 139 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 140 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 141 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 142 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 143 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 144 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 145 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 146 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 147 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 148 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 149 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 150 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 151 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 152 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 153 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 154 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 155 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 156 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 157 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 158 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 159 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 160 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 161 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 162 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 163 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 164 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 165 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 166 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 167 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 168 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 169 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 170 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 171 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 172 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 173 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 174 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 175 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 176 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 177 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 178 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 179 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 180 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 181 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 182 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 183 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 184 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 185 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 186 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 187 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 188 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 189 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 190 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 191 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 192 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 193 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 194 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 195 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 196 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 197 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 198 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 199 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 200 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 201 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 202 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 203 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 204 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 205 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 206 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 207 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 208 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 209 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 210 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 211 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 212 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 213 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 214 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 215 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 216 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 217 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 218 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 219 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 220 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 221 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 222 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 223 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 224 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 225 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 226 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 227 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 228 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 229 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 230 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 231 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 232 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 233 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 234 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 235 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 236 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 237 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 238 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 239 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 240 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 241 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 242 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 243 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 244 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 245 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 246 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 247 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 248 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 249 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 250 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 251 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 252 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 253 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 254 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 255 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 256 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 257 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 258 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 259 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 260 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 261 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 262 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 263 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 264 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 265 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 266 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 267 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 268 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 269 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 270 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 271 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 272 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 273 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 274 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 275 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 276 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 277 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 278 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 279 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 280 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 281 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 282 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 283 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 284 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 285 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 286 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 287 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 288 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 289 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 290 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 291 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 292 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 293 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 294 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 295 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 296 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 297 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 298 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 299 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n",
      "\u001b[95m=========== Search iteration : 300 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mPick hanoi_disk_2\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(2) Reward : \u001b[4m-1\u001b[0m\n",
      "Current logical action is None.. Reward is -10.0\n",
      "\u001b[95m[Reward]\u001b[0m S(2) -> A(None) -> S'(None) Reward : \u001b[4m-10.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# for idx, c in enumerate(c_list):\n",
    "mcts = MCTS(\n",
    "    scene_mngr=benchmark4.scene_mngr,\n",
    "    sampling_method=algo,\n",
    "    budgets=budgets,\n",
    "    max_depth=max_depth,\n",
    "    c=c_list[6],\n",
    "    debug_mode=debug_mode,\n",
    ")\n",
    "for i in range(budgets):\n",
    "#     print(\n",
    "#         f\"\\n[{idx+1}/{len(c_list)}] Benchmark: {benchmark3.scene_mngr.scene.bench_num}, Algo: {algo}, C: {c}, Seed: {seed}\"\n",
    "#     )\n",
    "    mcts.do_planning(i)\n",
    "\n",
    "final_level_1_values.append(mcts.values_for_level_1)\n",
    "final_level_2_values.append(mcts.values_for_level_2)\n",
    "\n",
    "if mcts.level_wise_2_success:\n",
    "    (\n",
    "        pnp_all_joint_paths,\n",
    "        pick_all_objects,\n",
    "        place_all_object_poses,\n",
    "    ) = mcts.get_all_joint_path(mcts.optimal_nodes)\n",
    "    final_pnp_all_joint_paths.append(pnp_all_joint_paths)\n",
    "    final_pick_all_objects.append(pick_all_objects)\n",
    "    final_place_all_object_poses.append(place_all_object_poses)\n",
    "    final_optimal_nodes.append(mcts.optimal_nodes)\n",
    "    \n",
    "    \n",
    "else:\n",
    "    final_pnp_all_joint_paths.append([])\n",
    "    final_pick_all_objects.append([])\n",
    "    final_place_all_object_poses.append([])\n",
    "    final_optimal_nodes.append([])\n",
    "    # final_optimal_trees.append(mcts.tree.nodes)\n",
    "#     del mcts\n",
    "#     # print(final_optimal_trees)\n",
    "#     print(\"delete mcts\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5da7941a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PWD :  /home/juju/pytamp/examples/doosan/action/rearrangement1\n",
      "Animation Finished..\n",
      "Save finished..\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mcts.place_action.simulate_path(\n",
    "    final_pnp_all_joint_paths[0],\n",
    "    final_pick_all_objects[0],\n",
    "    final_place_all_object_poses[0],\n",
    "    is_save=True,\n",
    "    video_name=\"benchmark4_MCTS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab257e40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TAMP_39",
   "language": "python",
   "name": "tamp_39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
