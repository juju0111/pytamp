{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30835fd6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 22:25:19.807721: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "usage: ipykernel_launcher.py [-h] [--budgets T] [--max_depth H] [--seed i]\n",
      "                             [--algo alg] [--debug_mode DEBUG_MODE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/juju/.local/share/jupyter/runtime/kernel-bcbdf8e7-c299-45fa-9d42-aa17b33aa3f8.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table  o_pose :  [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "ben_cube0  o_pose :  [[-0.99833062  0.05775794  0.         -0.34006171]\n",
      " [-0.05775794 -0.99833062  0.          0.59777838]\n",
      " [ 0.          0.          1.          0.79229998]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "bottle0  o_pose :  [[-0.44628384 -0.89489147  0.         -0.21132009]\n",
      " [ 0.89489147 -0.44628384  0.          0.49846736]\n",
      " [ 0.          0.          1.          0.83215735]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "can0  o_pose :  [[-0.98551936 -0.16956296  0.         -0.26125986]\n",
      " [ 0.16956296 -0.98551936  0.          0.87988355]\n",
      " [ 0.          0.          1.          0.80759666]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "cereal0  o_pose :  [[-0.67457655  0.7382049   0.         -0.47868132]\n",
      " [-0.7382049  -0.67457655  0.          0.41233326]\n",
      " [ 0.          0.          1.          0.84226188]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "table  o_pose :  [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "ben_cube0  o_pose :  [[ 0.45999483  0.8879216   0.         -0.42810585]\n",
      " [-0.8879216   0.45999483  0.          0.37137759]\n",
      " [ 0.          0.          1.          0.79229998]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "bottle0  o_pose :  [[ 0.46694576 -0.88428596  0.         -0.49587049]\n",
      " [ 0.88428596  0.46694576  0.          0.49820011]\n",
      " [ 0.          0.          1.          0.83215735]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "can0  o_pose :  [[-0.97112962  0.23855241  0.         -0.2354787 ]\n",
      " [-0.23855241 -0.97112962  0.          0.49858242]\n",
      " [ 0.          0.          1.          0.80759666]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "cereal0  o_pose :  [[-0.25346519  0.96734451  0.         -0.47985231]\n",
      " [-0.96734451 -0.25346519  0.          0.60883087]\n",
      " [ 0.          0.          1.          0.84226188]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "*********************** \u001b[92mLogical States\u001b[0m ***********************\n",
      "OrderedDict([('ben_cube0',\n",
      "              {'on': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043])}),\n",
      "             ('bottle0',\n",
      "              {'on': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043])}),\n",
      "             ('can0',\n",
      "              {'on': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043])}),\n",
      "             ('cereal0',\n",
      "              {'on': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043])}),\n",
      "             ('table',\n",
      "              {'static': True,\n",
      "               'support': [\u001b[95mObject\u001b[0m(name=ben_cube0, pos=[ 0.55993829 -0.00222162  0.83529998]),\n",
      "                           \u001b[95mObject\u001b[0m(name=bottle0, pos=[ 0.68867991 -0.10153264  0.87515735]),\n",
      "                           \u001b[95mObject\u001b[0m(name=can0, pos=[0.63874014 0.27988355 0.85059666]),\n",
      "                           \u001b[95mObject\u001b[0m(name=cereal0, pos=[ 0.42131868 -0.18766674  0.88526188])]}),\n",
      "             ('panda_gripper', {'holding': None})])\n",
      "***************************************************************\n",
      "\n",
      "*********************** \u001b[92mLogical States\u001b[0m ***********************\n",
      "OrderedDict([('ben_cube0',\n",
      "              {'on': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043])}),\n",
      "             ('bottle0',\n",
      "              {'on': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043])}),\n",
      "             ('can0',\n",
      "              {'on': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043])}),\n",
      "             ('cereal0',\n",
      "              {'on': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043])}),\n",
      "             ('table',\n",
      "              {'static': True,\n",
      "               'support': [\u001b[95mObject\u001b[0m(name=ben_cube0, pos=[ 0.47189415 -0.22862241  0.83529998]),\n",
      "                           \u001b[95mObject\u001b[0m(name=bottle0, pos=[ 0.40412951 -0.10179989  0.87515735]),\n",
      "                           \u001b[95mObject\u001b[0m(name=can0, pos=[ 0.6645213  -0.10141758  0.85059666]),\n",
      "                           \u001b[95mObject\u001b[0m(name=cereal0, pos=[0.42014769 0.00883087 0.88526188])]}),\n",
      "             ('panda_gripper', {'holding': None})])\n",
      "***************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os, time\n",
    "\n",
    "from pykin.utils import plot_utils as p_utils\n",
    "\n",
    "from pytamp.benchmark import Rearrange1\n",
    "from pytamp.benchmark.rearrange1 import make_scene\n",
    "from pytamp.search.mcts_for_rearragement import MCTS_rearrangement\n",
    "from pytamp.utils import point_cloud_utils as pc_utils\n",
    "\n",
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser(description=\"Test Rearragement 1.\")\n",
    "    parser.add_argument(\"--budgets\", metavar=\"T\", type=int, default=30, help=\"Horizon\")\n",
    "    parser.add_argument(\"--max_depth\", metavar=\"H\", type=int, default=14, help=\"Max depth\")\n",
    "#     parser.add_argument(\"--seed\", metavar=\"i\", type=int, default=7, help=\"A random seed\")\n",
    "#     parser.add_argument(\"--seed\", metavar=\"i\", type=int, default=17, help=\"A random seed\")\n",
    "    parser.add_argument(\"--seed\", metavar=\"i\", type=int, default=22, help=\"A random seed\")\n",
    "    parser.add_argument(\n",
    "        \"--algo\",\n",
    "        metavar=\"alg\",\n",
    "        type=str,\n",
    "        default=\"bai_perturb\",\n",
    "        choices=[\"bai_perturb\", \"bai_ucb\", \"uct\", \"random\", \"greedy\"],\n",
    "        help=\"Choose one (bai_perturb, bai_ucb, uct)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--debug_mode\", default=False, type=lambda x: (str(x).lower() == \"true\"), help=\"Debug mode\"\n",
    "    )\n",
    "#     parser.add_argument(\"--box_number\", metavar=\"N\", type=int, default=6, help=\"Box Number(6 or less)\")\n",
    "    try:\n",
    "        args = parser.parse_args() #call from command line\n",
    "    except:\n",
    "        args = parser.parse_args(args=[]) #call from notebook\n",
    "    return args \n",
    "\n",
    "args = get_parser() \n",
    "\n",
    "debug_mode = args.debug_mode\n",
    "# debug_mode = True\n",
    "budgets = args.budgets\n",
    "max_depth = args.max_depth\n",
    "algo = args.algo\n",
    "seed = args.seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "object_names, init_scene, goal_scene = make_scene()\n",
    "rearrangement1 = Rearrange1('panda', object_names, init_scene, goal_scene, is_pyplot=False)\n",
    "\n",
    "final_level_1_values = []\n",
    "final_level_2_values = []\n",
    "final_optimal_nodes = []\n",
    "final_pnp_all_joint_paths = []\n",
    "final_pick_all_objects = []\n",
    "final_place_all_object_poses = []\n",
    "\n",
    "# final_optimal_trees = []\n",
    "c_list = 10 ** np.linspace(-2, 2.0, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97474979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'table': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043]), 'ben_cube0': \u001b[95mObject\u001b[0m(name=ben_cube0, pos=[ 0.55993829 -0.00222162  0.83529998]), 'bottle0': \u001b[95mObject\u001b[0m(name=bottle0, pos=[ 0.68867991 -0.10153264  0.87515735]), 'can0': \u001b[95mObject\u001b[0m(name=can0, pos=[0.63874014 0.27988355 0.85059666]), 'cereal0': \u001b[95mObject\u001b[0m(name=cereal0, pos=[ 0.42131868 -0.18766674  0.88526188])}\n",
      "{'table': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043]), 'ben_cube0': \u001b[95mObject\u001b[0m(name=ben_cube0, pos=[ 0.47189415 -0.22862241  0.83529998]), 'bottle0': \u001b[95mObject\u001b[0m(name=bottle0, pos=[ 0.40412951 -0.10179989  0.87515735]), 'can0': \u001b[95mObject\u001b[0m(name=can0, pos=[ 0.6645213  -0.10141758  0.85059666]), 'cereal0': \u001b[95mObject\u001b[0m(name=cereal0, pos=[0.42014769 0.00883087 0.88526188])}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# #######################\n",
    "fig, ax = p_utils.init_3d_figure(name=\"Rearrangement 1\")\n",
    "# init_scene\n",
    "rearrangement1.scene_mngr.render_scene(ax)\n",
    "rearrangement1.render_axis(rearrangement1.scene_mngr)\n",
    "rearrangement1.scene_mngr.show()\n",
    "\n",
    "# goal_scene\n",
    "rearrangement1.goal_scene_mngr.render_scene(ax)\n",
    "rearrangement1.render_axis(rearrangement1.goal_scene_mngr)\n",
    "rearrangement1.goal_scene_mngr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "828caf6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 22:25:41.211721: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2023-08-03 22:25:41.237974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-03 22:25:41.238044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3080 computeCapability: 8.6\n",
      "coreClock: 1.74GHz coreCount: 68 deviceMemorySize: 9.77GiB deviceMemoryBandwidth: 707.88GiB/s\n",
      "2023-08-03 22:25:41.238065: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-08-03 22:25:41.239446: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-08-03 22:25:41.239495: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-08-03 22:25:41.239958: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2023-08-03 22:25:41.240082: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2023-08-03 22:25:41.240477: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-08-03 22:25:41.240849: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-08-03 22:25:41.240924: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-08-03 22:25:41.240997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-03 22:25:41.241063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-03 22:25:41.241102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/juju/contact_graspnet/pointnet2/tf_ops/sampling\n",
      "<module 'contact_graspnet.contact_graspnet' from '/home/juju/contact_graspnet/contact_graspnet/contact_graspnet.py'>\n",
      "--- Get model\n",
      "WARNING:tensorflow:From /home/juju/anaconda3/envs/contact_graspnet/lib/python3.8/site-packages/tensorflow/python/keras/layers/normalization.py:534: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juju/contact_graspnet/contact_graspnet/config_utils.py:42: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  global_config = yaml.load(f)\n",
      "/home/juju/anaconda3/envs/contact_graspnet/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/normalization.py:307: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  warnings.warn(\n",
      "/home/juju/anaconda3/envs/contact_graspnet/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/juju/anaconda3/envs/contact_graspnet/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:602: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "WARNING:tensorflow:From /home/juju/anaconda3/envs/contact_graspnet/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 22:25:43.394775: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-03 22:25:43.395788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-03 22:25:43.395864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3080 computeCapability: 8.6\n",
      "coreClock: 1.74GHz coreCount: 68 deviceMemorySize: 9.77GiB deviceMemoryBandwidth: 707.88GiB/s\n",
      "2023-08-03 22:25:43.395903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-03 22:25:43.395950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-03 22:25:43.395982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2023-08-03 22:25:43.396017: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/juju/contact_graspnet/checkpoints/scene_test_2048_bs3_hor_sigma_001/model.ckpt-144144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 22:25:43.661805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-08-03 22:25:43.661826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2023-08-03 22:25:43.661829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2023-08-03 22:25:43.661950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-03 22:25:43.662039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-03 22:25:43.662089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-03 22:25:43.662139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6765 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "2023-08-03 22:25:43.754680: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3609600000 Hz\n"
     ]
    }
   ],
   "source": [
    "c = 2.5\n",
    "idx = 0\n",
    "mcts = MCTS_rearrangement(\n",
    "        scene_mngr=rearrangement1.scene_mngr,\n",
    "        init_scene=rearrangement1.init_scene,\n",
    "        sampling_method=args.algo,\n",
    "        budgets=args.budgets,\n",
    "        max_depth=args.max_depth,\n",
    "        c=c,\n",
    "        debug_mode=args.debug_mode,\n",
    "        use_pick_action=False,\n",
    "        consider_next_scene=True, \n",
    "    )\n",
    "mcts.only_optimize_1 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b358eaf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 1 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(3) -> S'(8) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(8) -> A(11) -> S'(15) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(15) -> A(20) -> S'(22) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(22) -> A(24) -> S'(29) Reward : \u001b[4m2.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(29) -> A(34) -> S'(35) Reward : \u001b[4m1.667\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(35) -> A(39) -> S'(41) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(41) -> A(45) -> S'(46) Reward : \u001b[4m-2.857\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(46) -> A(51) -> S'(52) Reward : \u001b[4m1.111\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(52) -> A(54) -> S'(57) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(57) -> A(58) -> S'(62) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(62) -> A(63) -> S'(67) Reward : \u001b[4m0.833\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(67) -> A(72) -> S'(73) Reward : \u001b[4m0.769\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(73) -> A(74) -> S'(77) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(77) -> A(79) -> S'(81) Reward : \u001b[4m-1.429\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  1.1754405498504639 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 2 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(82) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(82) -> A(84) -> S'(88) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(88) -> A(93) -> S'(95) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(95) -> A(100) -> S'(101) Reward : \u001b[4m2.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(101) -> A(102) -> S'(107) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(107) -> A(110) -> S'(112) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(112) -> A(114) -> S'(117) Reward : \u001b[4m1.25\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(117) -> A(121) -> S'(122) Reward : \u001b[4m1.111\u001b[0m\n",
      "##########['bottle0', 'can0', 'ben_cube0', 'cereal0']#############\n",
      "\u001b[94mSuccess!!!!!\u001b[0m\n",
      "Terminal State! Reward is 5\n",
      "\u001b[0;33mben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 22:25:46.069701: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-08-03 22:25:46.412585: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8201\n",
      "2023-08-03 22:25:46.944027: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-08-03 22:25:47.231601: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2 grasps for object ben_cube0\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0047 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0017 sec\n",
      "\n",
      "\u001b[0;33mbottle0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 88 grasps for object bottle0\n",
      "solve with LM1\n",
      "Iterators : 12\n",
      "WorkingTime[inverse_kinematics]: 0.0058 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 6\n",
      "WorkingTime[inverse_kinematics]: 0.0030 sec\n",
      "\n",
      "\u001b[0;33mcereal0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 36 grasps for object cereal0\n",
      "solve with LM1\n",
      "Iterators : 18\n",
      "WorkingTime[inverse_kinematics]: 0.0085 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 31 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 13\n",
      "WorkingTime[inverse_kinematics]: 0.0084 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0023 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0017 sec\n",
      "\n",
      "\u001b[0;33mben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 20 grasps for object ben_cube0\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0084 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0017 sec\n",
      "\n",
      "\u001b[0;33mcereal0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 60 grasps for object cereal0\n",
      "solve with LM1\n",
      "Iterators : 8\n",
      "WorkingTime[inverse_kinematics]: 0.0041 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0017 sec\n",
      "\n",
      "\u001b[0;33mben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 8 grasps for object ben_cube0\n",
      "solve with LM1\n",
      "Iterators : 14\n",
      "WorkingTime[inverse_kinematics]: 0.0069 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0043 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 6\n",
      "WorkingTime[inverse_kinematics]: 0.0031 sec\n",
      "\n",
      "\u001b[0;33mcereal0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000001\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 107 grasps for object cereal0\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0045 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0017 sec\n",
      "\n",
      "level 1_5 :  [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "\u001b[1;33mpick ben_cube0\u001b[0m\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0044 sec\n",
      "\n",
      "rewire\n",
      "rewire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 3 --> 20\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000000\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.958\n",
      "WorkingTime[run]: 3.4433 sec\n",
      "\n",
      "WorkingTime[run]: 0.0504 sec\n",
      "\n",
      "WorkingTime[run]: 0.0500 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 3 --> 20\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000001\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 2.053\n",
      "WorkingTime[run]: 4.6372 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 13\n",
      "WorkingTime[inverse_kinematics]: 0.0067 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 4 --> 30\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000002\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 2.577\n",
      "WorkingTime[run]: 4.3279 sec\n",
      "\n",
      "WorkingTime[run]: 0.0505 sec\n",
      "\n",
      "WorkingTime[run]: 0.0505 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 8 --> 70\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000002\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 2.603\n",
      "WorkingTime[run]: 3.2625 sec\n",
      "\n",
      "Success pnp\n",
      "\u001b[1;33mpick bottle0\u001b[0m\n",
      "solve with LM1\n",
      "Iterators : 12\n",
      "WorkingTime[inverse_kinematics]: 0.0062 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 4 --> 30\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000002\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 2.558\n",
      "WorkingTime[run]: 3.4059 sec\n",
      "\n",
      "WorkingTime[run]: 0.0492 sec\n",
      "\n",
      "WorkingTime[run]: 0.0509 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 3 --> 20\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 2.428\n",
      "WorkingTime[run]: 4.5440 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 12\n",
      "WorkingTime[inverse_kinematics]: 0.0062 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 15\n",
      "WorkingTime[inverse_kinematics]: 0.0069 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 15\n",
      "WorkingTime[inverse_kinematics]: 0.0072 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 24\n",
      "WorkingTime[inverse_kinematics]: 0.0109 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 26\n",
      "WorkingTime[inverse_kinematics]: 0.0119 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 16\n",
      "WorkingTime[inverse_kinematics]: 0.0075 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 22\n",
      "WorkingTime[inverse_kinematics]: 0.0101 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 35\n",
      "WorkingTime[inverse_kinematics]: 0.0158 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 17\n",
      "WorkingTime[inverse_kinematics]: 0.0079 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 19\n",
      "WorkingTime[inverse_kinematics]: 0.0091 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 21\n",
      "WorkingTime[inverse_kinematics]: 0.0096 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 15\n",
      "WorkingTime[inverse_kinematics]: 0.0068 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 15\n",
      "WorkingTime[inverse_kinematics]: 0.0070 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 30\n",
      "WorkingTime[inverse_kinematics]: 0.0135 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 21\n",
      "WorkingTime[inverse_kinematics]: 0.0095 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 22\n",
      "WorkingTime[inverse_kinematics]: 0.0100 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 24\n",
      "WorkingTime[inverse_kinematics]: 0.0107 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 21\n",
      "WorkingTime[inverse_kinematics]: 0.0096 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 10 --> 90\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000004\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 4.037\n",
      "WorkingTime[run]: 4.4080 sec\n",
      "\n",
      "WorkingTime[run]: 0.0525 sec\n",
      "\n",
      "WorkingTime[run]: 0.0519 sec\n",
      "\n",
      "rewire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 5 --> 40\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000002\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 4.142\n",
      "WorkingTime[run]: 3.3243 sec\n",
      "\n",
      "Success pnp\n",
      "\u001b[1;33mpick cereal0\u001b[0m\n",
      "solve with LM1\n",
      "Iterators : 19\n",
      "WorkingTime[inverse_kinematics]: 0.0092 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 13\n",
      "WorkingTime[inverse_kinematics]: 0.0062 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31;21m[ERROR] [RRT Star Planner]: Failed Generate Path..\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000003\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRetry Generate Path, the number of retries is 1/5 \u001b[0m\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 16\n",
      "WorkingTime[inverse_kinematics]: 0.0079 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 11\n",
      "WorkingTime[inverse_kinematics]: 0.0052 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 12\n",
      "WorkingTime[inverse_kinematics]: 0.0058 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 14\n",
      "WorkingTime[inverse_kinematics]: 0.0066 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 12\n",
      "WorkingTime[inverse_kinematics]: 0.0057 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 11\n",
      "WorkingTime[inverse_kinematics]: 0.0052 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0043 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 16\n",
      "WorkingTime[inverse_kinematics]: 0.0074 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: iter : 500\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 6 --> 50\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 3.543\n",
      "WorkingTime[run]: 8.0869 sec\n",
      "\n",
      "WorkingTime[run]: 0.0505 sec\n",
      "\n",
      "WorkingTime[run]: 0.0471 sec\n",
      "\n",
      "rewire\n",
      "rewire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 6 --> 50\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000001\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 3.607\n",
      "WorkingTime[run]: 4.5936 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 15\n",
      "WorkingTime[inverse_kinematics]: 0.0074 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 14\n",
      "WorkingTime[inverse_kinematics]: 0.0066 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 23\n",
      "WorkingTime[inverse_kinematics]: 0.0105 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 23\n",
      "WorkingTime[inverse_kinematics]: 0.0105 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 11\n",
      "WorkingTime[inverse_kinematics]: 0.0053 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 19\n",
      "WorkingTime[inverse_kinematics]: 0.0086 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31;21m[ERROR] [RRT Star Planner]: Failed Generate Path..\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000001\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRetry Generate Path, the number of retries is 1/5 \u001b[0m\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 11\n",
      "WorkingTime[inverse_kinematics]: 0.0057 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 21\n",
      "WorkingTime[inverse_kinematics]: 0.0096 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 18\n",
      "WorkingTime[inverse_kinematics]: 0.0082 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 21\n",
      "WorkingTime[inverse_kinematics]: 0.0095 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 14\n",
      "WorkingTime[inverse_kinematics]: 0.0064 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 25\n",
      "WorkingTime[inverse_kinematics]: 0.0110 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 21\n",
      "WorkingTime[inverse_kinematics]: 0.0095 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 13\n",
      "WorkingTime[inverse_kinematics]: 0.0059 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 15\n",
      "WorkingTime[inverse_kinematics]: 0.0068 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 11\n",
      "WorkingTime[inverse_kinematics]: 0.0051 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 22\n",
      "WorkingTime[inverse_kinematics]: 0.0098 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: iter : 500\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 18 --> 170\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 4.963\n",
      "WorkingTime[run]: 10.7097 sec\n",
      "\n",
      "WorkingTime[run]: 0.0512 sec\n",
      "\n",
      "WorkingTime[run]: 0.0509 sec\n",
      "\n",
      "rewire\n",
      "rewire\n",
      "rewire\n",
      "rewire\n",
      "rewire\n",
      "rewire\n",
      "rewire\n",
      "rewire\n",
      "rewire\n",
      "rewire\n",
      "rewire\n",
      "rewire\n",
      "rewire\n",
      "rewire\n",
      "rewire\n",
      "rewire\n",
      "rewire\n",
      "rewire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 5 --> 40\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000001\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 4.988\n",
      "WorkingTime[run]: 3.2203 sec\n",
      "\n",
      "Success pnp\n",
      "\u001b[1;33mpick can0\u001b[0m\n",
      "solve with LM1\n",
      "Iterators : 13\n",
      "WorkingTime[inverse_kinematics]: 0.0098 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 7 --> 60\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 3.023\n",
      "WorkingTime[run]: 3.4067 sec\n",
      "\n",
      "WorkingTime[run]: 0.0506 sec\n",
      "\n",
      "WorkingTime[run]: 0.0490 sec\n",
      "\n",
      "rewire\n",
      "rewire\n",
      "rewire\n",
      "rewire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 5 --> 40\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000002\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 3.139\n",
      "WorkingTime[run]: 4.6722 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0046 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 3 --> 20\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 2.019\n",
      "WorkingTime[run]: 4.4054 sec\n",
      "\n",
      "WorkingTime[run]: 0.0476 sec\n",
      "\n",
      "WorkingTime[run]: 0.0545 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 3 --> 20\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000002\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.959\n",
      "WorkingTime[run]: 3.3001 sec\n",
      "\n",
      "Success pnp\n",
      "\u001b[1;33mpick ben_cube0\u001b[0m\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0086 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 3 --> 20\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.982\n",
      "WorkingTime[run]: 3.3953 sec\n",
      "\n",
      "WorkingTime[run]: 0.0496 sec\n",
      "\n",
      "WorkingTime[run]: 0.0506 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 3 --> 20\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000002\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.941\n",
      "WorkingTime[run]: 4.5897 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0048 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 6 --> 50\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.861\n",
      "WorkingTime[run]: 4.2874 sec\n",
      "\n",
      "WorkingTime[run]: 0.0502 sec\n",
      "\n",
      "WorkingTime[run]: 0.0475 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 3 --> 20\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000002\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.98\n",
      "WorkingTime[run]: 3.2779 sec\n",
      "\n",
      "Success pnp\n",
      "\u001b[1;33mpick cereal0\u001b[0m\n",
      "solve with LM1\n",
      "Iterators : 7\n",
      "WorkingTime[inverse_kinematics]: 0.0038 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 3 --> 20\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.381\n",
      "WorkingTime[run]: 3.4325 sec\n",
      "\n",
      "WorkingTime[run]: 0.0485 sec\n",
      "\n",
      "WorkingTime[run]: 0.0492 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 5 --> 40\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000004\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.391\n",
      "WorkingTime[run]: 4.4752 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 31\n",
      "WorkingTime[inverse_kinematics]: 0.0181 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 3 --> 20\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000003\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000016\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.794\n",
      "WorkingTime[run]: 4.3017 sec\n",
      "\n",
      "WorkingTime[run]: 0.0511 sec\n",
      "\n",
      "WorkingTime[run]: 0.0507 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 4 --> 30\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000002\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.839\n",
      "WorkingTime[run]: 3.3685 sec\n",
      "\n",
      "Success pnp\n",
      "\u001b[1;33mpick ben_cube0\u001b[0m\n",
      "solve with LM1\n",
      "Iterators : 15\n",
      "WorkingTime[inverse_kinematics]: 0.0075 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 3 --> 20\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000002\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000003\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 2.346\n",
      "WorkingTime[run]: 3.3328 sec\n",
      "\n",
      "WorkingTime[run]: 0.0487 sec\n",
      "\n",
      "WorkingTime[run]: 0.0506 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 8 --> 70\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000030\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 2.535\n",
      "WorkingTime[run]: 4.6963 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 13\n",
      "WorkingTime[inverse_kinematics]: 0.0066 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 12 --> 110\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000002\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 2.871\n",
      "WorkingTime[run]: 4.4176 sec\n",
      "\n",
      "WorkingTime[run]: 0.0520 sec\n",
      "\n",
      "WorkingTime[run]: 0.0632 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 4 --> 30\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000004\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 2.979\n",
      "WorkingTime[run]: 3.3227 sec\n",
      "\n",
      "Success pnp\n",
      "\u001b[1;33mpick cereal0\u001b[0m\n",
      "solve with LM1\n",
      "Iterators : 8\n",
      "WorkingTime[inverse_kinematics]: 0.0045 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 3 --> 20\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.795\n",
      "WorkingTime[run]: 3.2884 sec\n",
      "\n",
      "WorkingTime[run]: 0.0513 sec\n",
      "\n",
      "WorkingTime[run]: 0.0510 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 3 --> 20\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000001\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.783\n",
      "WorkingTime[run]: 4.5854 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 8\n",
      "WorkingTime[inverse_kinematics]: 0.0045 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 2 --> 10\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.245\n",
      "WorkingTime[run]: 4.2932 sec\n",
      "\n",
      "WorkingTime[run]: 0.0507 sec\n",
      "\n",
      "WorkingTime[run]: 0.0510 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 2 --> 10\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.259\n",
      "WorkingTime[run]: 3.2434 sec\n",
      "\n",
      "Success pnp\n",
      "\u001b[0;36mUpdate Sub optimal Nodes!! Value is 8.256744.\u001b[0m\n",
      "\u001b[95m level 2 value : 8.256744 \u001b[0m\n",
      "Add level_1_node!\n",
      "Add level_2_node!\n",
      "########### Running time :  144.10692882537842 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 3 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(2) -> S'(123) Reward : \u001b[4m5.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(123) -> A(126) -> S'(129) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(129) -> A(130) -> S'(135) Reward : \u001b[4m-6.667\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(135) -> A(137) -> S'(141) Reward : \u001b[4m2.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(141) -> A(146) -> S'(148) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(148) -> A(151) -> S'(153) Reward : \u001b[4m-3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(153) -> A(157) -> S'(159) Reward : \u001b[4m1.25\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(159) -> A(164) -> S'(166) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(166) -> A(169) -> S'(172) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(172) -> A(173) -> S'(178) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(178) -> A(182) -> S'(184) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(184) -> A(189) -> S'(190) Reward : \u001b[4m-1.667\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(190) -> A(191) -> S'(197) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(197) -> A(203) -> S'(204) Reward : \u001b[4m0.667\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  145.17260217666626 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 4 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(4) -> S'(205) Reward : \u001b[4m5.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(205) -> A(210) -> S'(212) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(212) -> A(217) -> S'(218) Reward : \u001b[4m2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(218) -> A(221) -> S'(224) Reward : \u001b[4m-5.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(224) -> A(225) -> S'(230) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(230) -> A(233) -> S'(236) Reward : \u001b[4m-3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(236) -> A(237) -> S'(243) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(243) -> A(245) -> S'(248) Reward : \u001b[4m1.111\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(248) -> A(250) -> S'(254) Reward : \u001b[4m1.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(254) -> A(258) -> S'(260) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(260) -> A(264) -> S'(265) Reward : \u001b[4m0.833\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(265) -> A(269) -> S'(270) Reward : \u001b[4m0.769\u001b[0m\n",
      "##########['bottle0', 'ben_cube0', 'can0', 'cereal0']#############\n",
      "\u001b[94mSuccess!!!!!\u001b[0m\n",
      "Terminal State! Reward is 5\n",
      "\u001b[0;33mbottle0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 58 grasps for object bottle0\n",
      "solve with LM1\n",
      "Iterators : 11\n",
      "WorkingTime[inverse_kinematics]: 0.0053 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "\u001b[0;33mcereal0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 53 grasps for object cereal0\n",
      "solve with LM1\n",
      "Iterators : 14\n",
      "WorkingTime[inverse_kinematics]: 0.0067 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 8\n",
      "WorkingTime[inverse_kinematics]: 0.0038 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 6\n",
      "WorkingTime[inverse_kinematics]: 0.0029 sec\n",
      "\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 24 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 13\n",
      "WorkingTime[inverse_kinematics]: 0.0061 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 7\n",
      "WorkingTime[inverse_kinematics]: 0.0034 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "\u001b[0;33mbottle0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 102 grasps for object bottle0\n",
      "solve with LM1\n",
      "Iterators : 10\n",
      "WorkingTime[inverse_kinematics]: 0.0054 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "\u001b[0;33mben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "\u001b[0;31mfailed to generate grasp pose for ben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "\u001b[0;31mfailed to generate grasp pose for ben_cube0\u001b[0m\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 17 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 10\n",
      "WorkingTime[inverse_kinematics]: 0.0049 sec\n",
      "\n",
      "collision !!! \n",
      "solve with LM1\n",
      "Iterators : 6\n",
      "WorkingTime[inverse_kinematics]: 0.0031 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0018 sec\n",
      "\n",
      "\u001b[0;33mben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 5 grasps for object ben_cube0\n",
      "solve with LM1\n",
      "Iterators : 8\n",
      "WorkingTime[inverse_kinematics]: 0.0044 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0016 sec\n",
      "\n",
      "\u001b[0;33mbottle0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 87 grasps for object bottle0\n",
      "solve with LM1\n",
      "Iterators : 14\n",
      "WorkingTime[inverse_kinematics]: 0.0067 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 6\n",
      "WorkingTime[inverse_kinematics]: 0.0030 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 6\n",
      "WorkingTime[inverse_kinematics]: 0.0029 sec\n",
      "\n",
      "\u001b[0;33mben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Random sample points \n",
      "Generated 12 grasps for object ben_cube0\n",
      "solve with LM1\n",
      "Iterators : 13\n",
      "WorkingTime[inverse_kinematics]: 0.0069 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "\u001b[0;33mcereal0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 63 grasps for object cereal0\n",
      "solve with LM1\n",
      "Iterators : 19\n",
      "WorkingTime[inverse_kinematics]: 0.0089 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0026 sec\n",
      "\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 12 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 13\n",
      "WorkingTime[inverse_kinematics]: 0.0063 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0026 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "\u001b[0;33mcereal0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Random sample points \n",
      "Generated 46 grasps for object cereal0\n",
      "solve with LM1\n",
      "Iterators : 8\n",
      "WorkingTime[inverse_kinematics]: 0.0044 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0016 sec\n",
      "\n",
      "\u001b[91mA value of this optimal nodes is lower than maximum value.\u001b[0m\n",
      "\u001b[95m level 2 value : 8.256744 \u001b[0m\n",
      "Add level_1_node!\n",
      "########### Running time :  150.3182508945465 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 5 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(5) -> S'(271) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(271) -> A(275) -> S'(278) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(278) -> A(282) -> S'(284) Reward : \u001b[4m2.5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(284) -> A(287) -> S'(289) Reward : \u001b[4m-5.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(289) -> A(290) -> S'(295) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(295) -> A(300) -> S'(301) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(301) -> A(306) -> S'(307) Reward : \u001b[4m-2.857\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(307) -> A(309) -> S'(313) Reward : \u001b[4m1.111\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(313) -> A(315) -> S'(319) Reward : \u001b[4m1.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(319) -> A(323) -> S'(324) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(324) -> A(326) -> S'(329) Reward : \u001b[4m-1.818\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(329) -> A(333) -> S'(335) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(335) -> A(340) -> S'(341) Reward : \u001b[4m0.714\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(341) -> A(345) -> S'(347) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  151.48059153556824 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 6 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(6) -> S'(348) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(348) -> A(351) -> S'(354) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(354) -> A(359) -> S'(361) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(361) -> A(366) -> S'(368) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(368) -> A(371) -> S'(375) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(375) -> A(380) -> S'(382) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(382) -> A(384) -> S'(388) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(388) -> A(393) -> S'(395) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(395) -> A(399) -> S'(401) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(401) -> A(407) -> S'(408) Reward : \u001b[4m0.909\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(408) -> A(409) -> S'(415) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(415) -> A(419) -> S'(421) Reward : \u001b[4m0.769\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(421) -> A(423) -> S'(427) Reward : \u001b[4m0.714\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(427) -> A(431) -> S'(432) Reward : \u001b[4m-1.429\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  152.56241822242737 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 7 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(7) -> S'(433) Reward : \u001b[4m5.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(433) -> A(435) -> S'(439) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(439) -> A(442) -> S'(444) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(444) -> A(447) -> S'(449) Reward : \u001b[4m2.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(449) -> A(451) -> S'(454) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(454) -> A(455) -> S'(457) Reward : \u001b[4m-3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(457) -> A(458) -> S'(461) Reward : \u001b[4m-2.857\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(461) -> A(465) -> S'(466) Reward : \u001b[4m-2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(466) -> A(472) -> S'(473) Reward : \u001b[4m1.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(473) -> A(474) -> S'(480) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(480) -> A(483) -> S'(486) Reward : \u001b[4m-1.818\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(486) -> A(491) -> S'(493) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(493) -> A(494) -> S'(500) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(500) -> A(502) -> S'(506) Reward : \u001b[4m0.667\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  153.64774751663208 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 8 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(82) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(82) -> A(83) -> S'(507) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(507) -> A(509) -> S'(513) Reward : \u001b[4m2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(513) -> A(516) -> S'(520) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(520) -> A(522) -> S'(526) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(526) -> A(529) -> S'(532) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(532) -> A(535) -> S'(538) Reward : \u001b[4m1.25\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(538) -> A(540) -> S'(543) Reward : \u001b[4m-2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(543) -> A(544) -> S'(548) Reward : \u001b[4m-2.222\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(548) -> A(553) -> S'(554) Reward : \u001b[4m0.909\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(554) -> A(559) -> S'(560) Reward : \u001b[4m0.833\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(560) -> A(563) -> S'(565) Reward : \u001b[4m-1.667\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(565) -> A(568) -> S'(570) Reward : \u001b[4m-1.538\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(570) -> A(574) -> S'(576) Reward : \u001b[4m0.667\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  154.74826407432556 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 9 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(82) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(82) -> A(85) -> S'(577) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(577) -> A(581) -> S'(583) Reward : \u001b[4m2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(583) -> A(585) -> S'(590) Reward : \u001b[4m2.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(590) -> A(593) -> S'(596) Reward : \u001b[4m1.667\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(596) -> A(598) -> S'(600) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(600) -> A(603) -> S'(604) Reward : \u001b[4m-2.857\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(604) -> A(608) -> S'(609) Reward : \u001b[4m1.111\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(609) -> A(612) -> S'(614) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(614) -> A(615) -> S'(618) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(618) -> A(620) -> S'(623) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(623) -> A(625) -> S'(628) Reward : \u001b[4m0.769\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(628) -> A(631) -> S'(632) Reward : \u001b[4m0.714\u001b[0m\n",
      "##########['bottle0', 'cereal0', 'ben_cube0', 'can0']#############\n",
      "\u001b[94mSuccess!!!!!\u001b[0m\n",
      "Terminal State! Reward is 5\n",
      "already has grasp_poses\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 22 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 14\n",
      "WorkingTime[inverse_kinematics]: 0.0066 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 7\n",
      "WorkingTime[inverse_kinematics]: 0.0034 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "\u001b[0;33mbottle0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 56 grasps for object bottle0\n",
      "solve with LM1\n",
      "Iterators : 19\n",
      "WorkingTime[inverse_kinematics]: 0.0087 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 10\n",
      "WorkingTime[inverse_kinematics]: 0.0046 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 8\n",
      "WorkingTime[inverse_kinematics]: 0.0038 sec\n",
      "\n",
      "\u001b[0;33mben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 7 grasps for object ben_cube0\n",
      "Augment 2 y axis rotation from -pi/3 ~ pi/3 :  (42, 4, 4)\n",
      "Collision free grasps step 3 :  (3, 4, 4)\n",
      "solve with LM1\n",
      "Iterators : 55\n",
      "WorkingTime[inverse_kinematics]: 0.0254 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 1\n",
      "WorkingTime[inverse_kinematics]: 0.0011 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 1\n",
      "WorkingTime[inverse_kinematics]: 0.0010 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 1\n",
      "WorkingTime[inverse_kinematics]: 0.0010 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 1\n",
      "WorkingTime[inverse_kinematics]: 0.0010 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0028 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 1\n",
      "WorkingTime[inverse_kinematics]: 0.0010 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 1\n",
      "WorkingTime[inverse_kinematics]: 0.0010 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 1\n",
      "WorkingTime[inverse_kinematics]: 0.0010 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 1\n",
      "WorkingTime[inverse_kinematics]: 0.0013 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 100\n",
      "WorkingTime[inverse_kinematics]: 0.0442 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 12\n",
      "WorkingTime[inverse_kinematics]: 0.0059 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 1\n",
      "WorkingTime[inverse_kinematics]: 0.0010 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 1\n",
      "WorkingTime[inverse_kinematics]: 0.0010 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 1\n",
      "WorkingTime[inverse_kinematics]: 0.0010 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 1\n",
      "WorkingTime[inverse_kinematics]: 0.0010 sec\n",
      "\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 56 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0045 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0016 sec\n",
      "\n",
      "\u001b[0;33mcereal0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 68 grasps for object cereal0\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0044 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 31 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 100\n",
      "WorkingTime[inverse_kinematics]: 0.0437 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 100\n",
      "WorkingTime[inverse_kinematics]: 0.0434 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 100\n",
      "WorkingTime[inverse_kinematics]: 0.0436 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 100\n",
      "WorkingTime[inverse_kinematics]: 0.0437 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 100\n",
      "WorkingTime[inverse_kinematics]: 0.0445 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 14\n",
      "WorkingTime[inverse_kinematics]: 0.0066 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 6\n",
      "WorkingTime[inverse_kinematics]: 0.0030 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "\u001b[0;33mcereal0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 90 grasps for object cereal0\n",
      "solve with LM1\n",
      "Iterators : 15\n",
      "WorkingTime[inverse_kinematics]: 0.0072 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0016 sec\n",
      "\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 29 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 10\n",
      "WorkingTime[inverse_kinematics]: 0.0050 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0018 sec\n",
      "\n",
      "\u001b[0;33mben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 17 grasps for object ben_cube0\n",
      "solve with LM1\n",
      "Iterators : 10\n",
      "WorkingTime[inverse_kinematics]: 0.0048 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 25 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 8\n",
      "WorkingTime[inverse_kinematics]: 0.0040 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0020 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0016 sec\n",
      "\n",
      "\u001b[0;33mben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 20 grasps for object ben_cube0\n",
      "solve with LM1\n",
      "Iterators : 12\n",
      "WorkingTime[inverse_kinematics]: 0.0057 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 155 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 11\n",
      "WorkingTime[inverse_kinematics]: 0.0055 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0016 sec\n",
      "\n",
      "\u001b[91mA value of this optimal nodes is lower than maximum value.\u001b[0m\n",
      "\u001b[95m level 2 value : 8.256744 \u001b[0m\n",
      "Add level_1_node!\n",
      "########### Running time :  159.8748586177826 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 10 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(4) -> S'(205) Reward : \u001b[4m5.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(205) -> A(206) -> S'(633) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(633) -> A(636) -> S'(638) Reward : \u001b[4m2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(638) -> A(640) -> S'(644) Reward : \u001b[4m2.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(644) -> A(648) -> S'(649) Reward : \u001b[4m1.667\u001b[0m\n",
      "##########['bottle0', 'can0', 'ben_cube0', 'cereal0']#############\n",
      "\u001b[94mSuccess!!!!!\u001b[0m\n",
      "Terminal State! Reward is 5\n",
      "already has grasp_poses\n",
      "\u001b[0;33mben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 26 grasps for object ben_cube0\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0045 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0027 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0022 sec\n",
      "\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 158 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 10\n",
      "WorkingTime[inverse_kinematics]: 0.0050 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0017 sec\n",
      "\n",
      "\u001b[0;33mben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mfailed to generate grasp pose for ben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 5 grasps for object ben_cube0\n",
      "solve with LM1\n",
      "Iterators : 14\n",
      "WorkingTime[inverse_kinematics]: 0.0067 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "\u001b[0;33mcereal0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000001\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 55 grasps for object cereal0\n",
      "solve with LM1\n",
      "Iterators : 7\n",
      "WorkingTime[inverse_kinematics]: 0.0035 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0016 sec\n",
      "\n",
      "level 1_5 :  [True, True, True, True, True, True, True, True, True, True]\n",
      "\u001b[1;33mpick bottle0\u001b[0m\n",
      "solve with LM1\n",
      "Iterators : 11\n",
      "WorkingTime[inverse_kinematics]: 0.0053 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 4 --> 30\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 2.54\n",
      "WorkingTime[run]: 3.3712 sec\n",
      "\n",
      "WorkingTime[run]: 0.0504 sec\n",
      "\n",
      "WorkingTime[run]: 0.0501 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 4 --> 30\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000002\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 2.641\n",
      "WorkingTime[run]: 4.4672 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 23\n",
      "WorkingTime[inverse_kinematics]: 0.0111 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 8 --> 70\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000004\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000005\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 3.409\n",
      "WorkingTime[run]: 4.3632 sec\n",
      "\n",
      "WorkingTime[run]: 0.0517 sec\n",
      "\n",
      "WorkingTime[run]: 0.0514 sec\n",
      "\n",
      "rewire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 5 --> 40\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000002\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 3.572\n",
      "WorkingTime[run]: 3.3426 sec\n",
      "\n",
      "Success pnp\n",
      "\u001b[1;33mpick ben_cube0\u001b[0m\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0047 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 3 --> 20\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.677\n",
      "WorkingTime[run]: 3.3836 sec\n",
      "\n",
      "WorkingTime[run]: 0.0500 sec\n",
      "\n",
      "WorkingTime[run]: 0.0518 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 4 --> 30\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000011\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.848\n",
      "WorkingTime[run]: 4.6626 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 10\n",
      "WorkingTime[inverse_kinematics]: 0.0055 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 3 --> 20\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.894\n",
      "WorkingTime[run]: 4.4075 sec\n",
      "\n",
      "WorkingTime[run]: 0.0495 sec\n",
      "\n",
      "WorkingTime[run]: 0.0567 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 6 --> 50\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000002\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.901\n",
      "WorkingTime[run]: 3.3616 sec\n",
      "\n",
      "Success pnp\n",
      "\u001b[1;33mpick can0\u001b[0m\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0071 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 3 --> 20\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000000\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.696\n",
      "WorkingTime[run]: 3.3783 sec\n",
      "\n",
      "WorkingTime[run]: 0.0511 sec\n",
      "\n",
      "WorkingTime[run]: 0.0532 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 4 --> 30\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000001\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 2.078\n",
      "WorkingTime[run]: 4.7263 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 10\n",
      "WorkingTime[inverse_kinematics]: 0.0054 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 3 --> 20\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.915\n",
      "WorkingTime[run]: 4.4168 sec\n",
      "\n",
      "WorkingTime[run]: 0.0506 sec\n",
      "\n",
      "WorkingTime[run]: 0.0496 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 4 --> 30\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000001\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 2.343\n",
      "WorkingTime[run]: 3.2920 sec\n",
      "\n",
      "Success pnp\n",
      "\u001b[1;33mpick ben_cube0\u001b[0m\n",
      "solve with LM1\n",
      "Iterators : 14\n",
      "WorkingTime[inverse_kinematics]: 0.0069 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 4 --> 30\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 2.94\n",
      "WorkingTime[run]: 3.3024 sec\n",
      "\n",
      "WorkingTime[run]: 0.0486 sec\n",
      "\n",
      "WorkingTime[run]: 0.0512 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 5 --> 40\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000003\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 3.04\n",
      "WorkingTime[run]: 4.6636 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0051 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 6 --> 50\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 2.196\n",
      "WorkingTime[run]: 4.5151 sec\n",
      "\n",
      "WorkingTime[run]: 0.0510 sec\n",
      "\n",
      "WorkingTime[run]: 0.0503 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 3 --> 20\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000002\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 2.299\n",
      "WorkingTime[run]: 3.3757 sec\n",
      "\n",
      "Success pnp\n",
      "\u001b[1;33mpick cereal0\u001b[0m\n",
      "solve with LM1\n",
      "Iterators : 7\n",
      "WorkingTime[inverse_kinematics]: 0.0039 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 2 --> 10\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.179\n",
      "WorkingTime[run]: 3.4099 sec\n",
      "\n",
      "WorkingTime[run]: 0.0501 sec\n",
      "\n",
      "WorkingTime[run]: 0.0517 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 2 --> 10\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: The joint limit has been successfully checked. Pose error is 0.000005\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.147\n",
      "WorkingTime[run]: 4.5533 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 6\n",
      "WorkingTime[inverse_kinematics]: 0.0035 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 3 --> 20\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Start to compute Cartesian Planning\u001b[0m\n",
      "\u001b[1;32m[INFO] [Cartesian Planner]: Generate Path Successfully!! Error is 0.000001\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Start to compute RRT-star Planning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.1\n",
      "WorkingTime[run]: 4.4994 sec\n",
      "\n",
      "WorkingTime[run]: 0.0519 sec\n",
      "\n",
      "WorkingTime[run]: 0.0510 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[INFO] [RRT Star Planner]: Generate Path Successfully!!\u001b[0m\n",
      "\u001b[1;32m[INFO] [RRT Star Planner]: Path length 2 --> 10\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 1.132\n",
      "WorkingTime[run]: 3.2286 sec\n",
      "\n",
      "Success pnp\n",
      "\u001b[0;36mUpdate Sub optimal Nodes!! Value is 14.931767.\u001b[0m\n",
      "\u001b[95m level 2 value : 14.931767 \u001b[0m\n",
      "Add level_1_node!\n",
      "Add level_2_node!\n",
      "########### Running time :  241.74207043647766 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 11 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(4) -> S'(205) Reward : \u001b[4m5.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(205) -> A(207) -> S'(650) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(650) -> A(653) -> S'(655) Reward : \u001b[4m2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(655) -> A(656) -> S'(658) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(658) -> A(661) -> S'(662) Reward : \u001b[4m-4.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(662) -> A(666) -> S'(667) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(667) -> A(670) -> S'(671) Reward : \u001b[4m1.25\u001b[0m\n",
      "##########['bottle0', 'ben_cube0', 'cereal0', 'can0']#############\n",
      "\u001b[94mSuccess!!!!!\u001b[0m\n",
      "Terminal State! Reward is 5\n",
      "already has grasp_poses\n",
      "\u001b[0;33mben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 7 grasps for object ben_cube0\n",
      "solve with LM1\n",
      "Iterators : 12\n",
      "WorkingTime[inverse_kinematics]: 0.0084 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 7\n",
      "WorkingTime[inverse_kinematics]: 0.0034 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 7\n",
      "WorkingTime[inverse_kinematics]: 0.0034 sec\n",
      "\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 82 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 15\n",
      "WorkingTime[inverse_kinematics]: 0.0069 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 6\n",
      "WorkingTime[inverse_kinematics]: 0.0029 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "\u001b[0;33mcereal0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 75 grasps for object cereal0\n",
      "solve with LM1\n",
      "Iterators : 7\n",
      "WorkingTime[inverse_kinematics]: 0.0036 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0016 sec\n",
      "\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 24 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 11\n",
      "WorkingTime[inverse_kinematics]: 0.0053 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "\u001b[0;33mcereal0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 108 grasps for object cereal0\n",
      "solve with LM1\n",
      "Iterators : 12\n",
      "WorkingTime[inverse_kinematics]: 0.0058 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0026 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 30 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 10\n",
      "WorkingTime[inverse_kinematics]: 0.0074 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "\u001b[91mA value of this optimal nodes is lower than maximum value.\u001b[0m\n",
      "\u001b[95m level 2 value : 14.931767 \u001b[0m\n",
      "Add level_1_node!\n",
      "########### Running time :  244.2040250301361 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 12 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(4) -> S'(205) Reward : \u001b[4m5.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(205) -> A(208) -> S'(672) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(672) -> A(673) -> S'(678) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(678) -> A(683) -> S'(684) Reward : \u001b[4m2.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(684) -> A(685) -> S'(689) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(689) -> A(691) -> S'(694) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(694) -> A(695) -> S'(698) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(698) -> A(700) -> S'(702) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(702) -> A(704) -> S'(707) Reward : \u001b[4m1.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(707) -> A(709) -> S'(712) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(712) -> A(715) -> S'(716) Reward : \u001b[4m-1.818\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(716) -> A(719) -> S'(721) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(721) -> A(722) -> S'(726) Reward : \u001b[4m-1.538\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(726) -> A(729) -> S'(732) Reward : \u001b[4m0.667\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  245.1688368320465 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 13 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(82) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(82) -> A(86) -> S'(733) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(733) -> A(736) -> S'(739) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(739) -> A(744) -> S'(746) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(746) -> A(751) -> S'(753) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(753) -> A(755) -> S'(759) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(759) -> A(764) -> S'(765) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(765) -> A(766) -> S'(771) Reward : \u001b[4m-2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(771) -> A(776) -> S'(777) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(777) -> A(780) -> S'(784) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(784) -> A(786) -> S'(790) Reward : \u001b[4m0.833\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(790) -> A(791) -> S'(796) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(796) -> A(798) -> S'(801) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(801) -> A(806) -> S'(807) Reward : \u001b[4m0.667\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  246.33531594276428 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 14 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(4) -> S'(205) Reward : \u001b[4m5.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(205) -> A(209) -> S'(808) Reward : \u001b[4m3.333\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(808) -> A(813) -> S'(814) Reward : \u001b[4m2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(814) -> A(815) -> S'(819) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(819) -> A(820) -> S'(823) Reward : \u001b[4m-4.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(823) -> A(827) -> S'(828) Reward : \u001b[4m-3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(828) -> A(830) -> S'(834) Reward : \u001b[4m1.25\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(834) -> A(836) -> S'(840) Reward : \u001b[4m1.111\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(840) -> A(843) -> S'(845) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(845) -> A(846) -> S'(848) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(848) -> A(850) -> S'(852) Reward : \u001b[4m-1.818\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(852) -> A(854) -> S'(857) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(857) -> A(860) -> S'(862) Reward : \u001b[4m0.714\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(862) -> A(863) -> S'(868) Reward : \u001b[4m-1.429\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  247.31853342056274 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 15 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(82) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(82) -> A(87) -> S'(869) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(869) -> A(870) -> S'(875) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(875) -> A(879) -> S'(880) Reward : \u001b[4m-5.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(880) -> A(885) -> S'(886) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(886) -> A(889) -> S'(893) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(893) -> A(898) -> S'(900) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(900) -> A(905) -> S'(906) Reward : \u001b[4m1.111\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(906) -> A(909) -> S'(913) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(913) -> A(916) -> S'(918) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(918) -> A(921) -> S'(924) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(924) -> A(927) -> S'(930) Reward : \u001b[4m-1.667\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(930) -> A(931) -> S'(936) Reward : \u001b[4m0.714\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(936) -> A(941) -> S'(942) Reward : \u001b[4m0.667\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  248.31240463256836 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 16 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(4) -> S'(205) Reward : \u001b[4m5.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(205) -> A(211) -> S'(943) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(943) -> A(948) -> S'(949) Reward : \u001b[4m2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(949) -> A(950) -> S'(954) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(954) -> A(957) -> S'(958) Reward : \u001b[4m-4.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(958) -> A(962) -> S'(963) Reward : \u001b[4m-3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(963) -> A(965) -> S'(969) Reward : \u001b[4m1.25\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(969) -> A(970) -> S'(974) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(974) -> A(977) -> S'(979) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(979) -> A(981) -> S'(984) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(984) -> A(988) -> S'(990) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(990) -> A(991) -> S'(996) Reward : \u001b[4m-1.667\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(996) -> A(1001) -> S'(1003) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1003) -> A(1007) -> S'(1010) Reward : \u001b[4m0.667\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  249.31331372261047 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 17 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(82) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(82) -> A(84) -> S'(88) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(88) -> A(89) -> S'(1011) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1011) -> A(1013) -> S'(1016) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1016) -> A(1019) -> S'(1022) Reward : \u001b[4m-4.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1022) -> A(1027) -> S'(1029) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1029) -> A(1034) -> S'(1036) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1036) -> A(1041) -> S'(1042) Reward : \u001b[4m1.111\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1042) -> A(1046) -> S'(1049) Reward : \u001b[4m1.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1049) -> A(1051) -> S'(1054) Reward : \u001b[4m0.909\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1054) -> A(1055) -> S'(1059) Reward : \u001b[4m-1.818\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1059) -> A(1061) -> S'(1064) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1064) -> A(1066) -> S'(1068) Reward : \u001b[4m0.714\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1068) -> A(1069) -> S'(1073) Reward : \u001b[4m-1.429\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  250.41658449172974 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 18 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(4) -> S'(205) Reward : \u001b[4m5.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(205) -> A(206) -> S'(633) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(633) -> A(634) -> S'(1074) Reward : \u001b[4m-6.667\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1074) -> A(1080) -> S'(1081) Reward : \u001b[4m2.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1081) -> A(1086) -> S'(1088) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1088) -> A(1092) -> S'(1094) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1094) -> A(1095) -> S'(1100) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1100) -> A(1104) -> S'(1105) Reward : \u001b[4m-2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1105) -> A(1106) -> S'(1111) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1111) -> A(1113) -> S'(1115) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1115) -> A(1117) -> S'(1121) Reward : \u001b[4m0.833\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1121) -> A(1124) -> S'(1127) Reward : \u001b[4m0.769\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1127) -> A(1130) -> S'(1131) Reward : \u001b[4m0.714\u001b[0m\n",
      "##########['bottle0', 'ben_cube0', 'can0', 'cereal0']#############\n",
      "\u001b[94mSuccess!!!!!\u001b[0m\n",
      "Terminal State! Reward is 5\n",
      "already has grasp_poses\n",
      "already has grasp_poses\n",
      "\u001b[0;33mbottle0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 127 grasps for object bottle0\n",
      "solve with LM1\n",
      "Iterators : 13\n",
      "WorkingTime[inverse_kinematics]: 0.0078 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "\u001b[0;33mcereal0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 170 grasps for object cereal0\n",
      "solve with LM1\n",
      "Iterators : 17\n",
      "WorkingTime[inverse_kinematics]: 0.0079 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 36 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0044 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "\u001b[0;33mbottle0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 93 grasps for object bottle0\n",
      "solve with LM1\n",
      "Iterators : 12\n",
      "WorkingTime[inverse_kinematics]: 0.0057 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "\u001b[0;33mben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 7 grasps for object ben_cube0\n",
      "solve with LM1\n",
      "Iterators : 13\n",
      "WorkingTime[inverse_kinematics]: 0.0131 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 6\n",
      "WorkingTime[inverse_kinematics]: 0.0031 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "\u001b[0;33mcereal0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 54 grasps for object cereal0\n",
      "solve with LM1\n",
      "Iterators : 7\n",
      "WorkingTime[inverse_kinematics]: 0.0035 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0022 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0016 sec\n",
      "\n",
      "\u001b[0;33mben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 31 grasps for object ben_cube0\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0165 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0061 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0035 sec\n",
      "\n",
      "\u001b[0;33mcereal0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 62 grasps for object cereal0\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0045 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0017 sec\n",
      "\n",
      "\u001b[0;33mben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 13 grasps for object ben_cube0\n",
      "solve with LM1\n",
      "Iterators : 12\n",
      "WorkingTime[inverse_kinematics]: 0.0140 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 52 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 12\n",
      "WorkingTime[inverse_kinematics]: 0.0114 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 7\n",
      "WorkingTime[inverse_kinematics]: 0.0070 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0026 sec\n",
      "\n",
      "\u001b[0;33mcereal0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 55 grasps for object cereal0\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0047 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0022 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0026 sec\n",
      "\n",
      "\u001b[91mA value of this optimal nodes is lower than maximum value.\u001b[0m\n",
      "\u001b[95m level 2 value : 14.931767 \u001b[0m\n",
      "Add level_1_node!\n",
      "########### Running time :  254.9101390838623 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 19 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(82) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(82) -> A(85) -> S'(577) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(577) -> A(578) -> S'(1132) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1132) -> A(1136) -> S'(1138) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1138) -> A(1140) -> S'(1144) Reward : \u001b[4m1.667\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1144) -> A(1145) -> S'(1150) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1150) -> A(1155) -> S'(1156) Reward : \u001b[4m1.25\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1156) -> A(1160) -> S'(1162) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1162) -> A(1166) -> S'(1167) Reward : \u001b[4m-2.222\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1167) -> A(1169) -> S'(1173) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1173) -> A(1174) -> S'(1179) Reward : \u001b[4m-1.818\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1179) -> A(1181) -> S'(1186) Reward : \u001b[4m0.769\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1186) -> A(1187) -> S'(1193) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1193) -> A(1196) -> S'(1198) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  255.8849802017212 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 20 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(4) -> S'(205) Reward : \u001b[4m5.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(205) -> A(207) -> S'(650) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(650) -> A(651) -> S'(1199) Reward : \u001b[4m-6.667\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1199) -> A(1203) -> S'(1205) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1205) -> A(1209) -> S'(1210) Reward : \u001b[4m1.667\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1210) -> A(1213) -> S'(1216) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1216) -> A(1217) -> S'(1220) Reward : \u001b[4m-2.857\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1220) -> A(1221) -> S'(1225) Reward : \u001b[4m-2.5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1225) -> A(1227) -> S'(1230) Reward : \u001b[4m1.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1230) -> A(1234) -> S'(1236) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1236) -> A(1238) -> S'(1241) Reward : \u001b[4m0.833\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1241) -> A(1245) -> S'(1246) Reward : \u001b[4m0.769\u001b[0m\n",
      "##########['bottle0', 'can0', 'ben_cube0', 'cereal0']#############\n",
      "\u001b[94mSuccess!!!!!\u001b[0m\n",
      "Terminal State! Reward is 5\n",
      "already has grasp_poses\n",
      "already has grasp_poses\n",
      "\u001b[0;33mbottle0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 59 grasps for object bottle0\n",
      "solve with LM1\n",
      "Iterators : 8\n",
      "WorkingTime[inverse_kinematics]: 0.0040 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0017 sec\n",
      "\n",
      "\u001b[0;33mcereal0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 101 grasps for object cereal0\n",
      "solve with LM1\n",
      "Iterators : 11\n",
      "WorkingTime[inverse_kinematics]: 0.0053 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 6\n",
      "WorkingTime[inverse_kinematics]: 0.0030 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0026 sec\n",
      "\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 41 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 13\n",
      "WorkingTime[inverse_kinematics]: 0.0064 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 1\n",
      "WorkingTime[inverse_kinematics]: 0.0011 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 1\n",
      "WorkingTime[inverse_kinematics]: 0.0010 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 1\n",
      "WorkingTime[inverse_kinematics]: 0.0010 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 1\n",
      "WorkingTime[inverse_kinematics]: 0.0010 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 6\n",
      "WorkingTime[inverse_kinematics]: 0.0033 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 1\n",
      "WorkingTime[inverse_kinematics]: 0.0010 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 1\n",
      "WorkingTime[inverse_kinematics]: 0.0010 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 1\n",
      "WorkingTime[inverse_kinematics]: 0.0010 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 1\n",
      "WorkingTime[inverse_kinematics]: 0.0010 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 11\n",
      "WorkingTime[inverse_kinematics]: 0.0052 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0017 sec\n",
      "\n",
      "\u001b[0;33mbottle0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 102 grasps for object bottle0\n",
      "solve with LM1\n",
      "Iterators : 19\n",
      "WorkingTime[inverse_kinematics]: 0.0090 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 10\n",
      "WorkingTime[inverse_kinematics]: 0.0048 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0043 sec\n",
      "\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 88 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 100\n",
      "WorkingTime[inverse_kinematics]: 0.0439 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 100\n",
      "WorkingTime[inverse_kinematics]: 0.0437 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 100\n",
      "WorkingTime[inverse_kinematics]: 0.0435 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 100\n",
      "WorkingTime[inverse_kinematics]: 0.0436 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 100\n",
      "WorkingTime[inverse_kinematics]: 0.0443 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 8\n",
      "WorkingTime[inverse_kinematics]: 0.0038 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0020 sec\n",
      "\n",
      "\u001b[0;33mben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 5 grasps for object ben_cube0\n",
      "solve with LM1\n",
      "Iterators : 8\n",
      "WorkingTime[inverse_kinematics]: 0.0040 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 115 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 12\n",
      "WorkingTime[inverse_kinematics]: 0.0058 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0018 sec\n",
      "\n",
      "\u001b[0;33mcereal0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 171 grasps for object cereal0\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0045 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0026 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0017 sec\n",
      "\n",
      "\u001b[0;33mben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 15 grasps for object ben_cube0\n",
      "solve with LM1\n",
      "Iterators : 12\n",
      "WorkingTime[inverse_kinematics]: 0.0057 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 6\n",
      "WorkingTime[inverse_kinematics]: 0.0029 sec\n",
      "\n",
      "\u001b[0;33mcereal0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 79 grasps for object cereal0\n",
      "solve with LM1\n",
      "Iterators : 12\n",
      "WorkingTime[inverse_kinematics]: 0.0062 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 10\n",
      "WorkingTime[inverse_kinematics]: 0.0048 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 8\n",
      "WorkingTime[inverse_kinematics]: 0.0039 sec\n",
      "\n",
      "\u001b[91mA value of this optimal nodes is lower than maximum value.\u001b[0m\n",
      "\u001b[95m level 2 value : 14.931767 \u001b[0m\n",
      "Add level_1_node!\n",
      "########### Running time :  260.1776194572449 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 21 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(82) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(82) -> A(84) -> S'(88) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(88) -> A(90) -> S'(1247) Reward : \u001b[4m2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1247) -> A(1251) -> S'(1253) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1253) -> A(1257) -> S'(1258) Reward : \u001b[4m1.667\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1258) -> A(1259) -> S'(1262) Reward : \u001b[4m-3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1262) -> A(1264) -> S'(1267) Reward : \u001b[4m-2.857\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1267) -> A(1270) -> S'(1271) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1271) -> A(1275) -> S'(1277) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1277) -> A(1281) -> S'(1282) Reward : \u001b[4m0.909\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1282) -> A(1287) -> S'(1288) Reward : \u001b[4m0.833\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1288) -> A(1289) -> S'(1293) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1293) -> A(1295) -> S'(1297) Reward : \u001b[4m-1.538\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1297) -> A(1300) -> S'(1302) Reward : \u001b[4m-1.429\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  261.05196619033813 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 22 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(4) -> S'(205) Reward : \u001b[4m5.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(205) -> A(206) -> S'(633) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(633) -> A(635) -> S'(1303) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1303) -> A(1307) -> S'(1309) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1309) -> A(1311) -> S'(1315) Reward : \u001b[4m1.667\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1315) -> A(1318) -> S'(1321) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1321) -> A(1324) -> S'(1326) Reward : \u001b[4m-1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1326) -> A(1329) -> S'(1330) Reward : \u001b[4m-2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1330) -> A(1332) -> S'(1335) Reward : \u001b[4m-2.222\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1335) -> A(1338) -> S'(1341) Reward : \u001b[4m0.909\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1341) -> A(1343) -> S'(1346) Reward : \u001b[4m0.833\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1346) -> A(1348) -> S'(1351) Reward : \u001b[4m-1.667\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1351) -> A(1353) -> S'(1356) Reward : \u001b[4m-1.538\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1356) -> A(1360) -> S'(1362) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  262.1416265964508 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 23 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(82) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(82) -> A(85) -> S'(577) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(577) -> A(579) -> S'(1363) Reward : \u001b[4m2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1363) -> A(1366) -> S'(1369) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1369) -> A(1372) -> S'(1374) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1374) -> A(1376) -> S'(1378) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1378) -> A(1383) -> S'(1384) Reward : \u001b[4m1.25\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1384) -> A(1385) -> S'(1389) Reward : \u001b[4m-2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1389) -> A(1392) -> S'(1394) Reward : \u001b[4m1.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1394) -> A(1395) -> S'(1400) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1400) -> A(1401) -> S'(1404) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1404) -> A(1405) -> S'(1409) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1409) -> A(1411) -> S'(1414) Reward : \u001b[4m0.714\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1414) -> A(1416) -> S'(1418) Reward : \u001b[4m-1.429\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  263.0671684741974 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 24 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(4) -> S'(205) Reward : \u001b[4m5.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(205) -> A(207) -> S'(650) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(650) -> A(652) -> S'(1419) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1419) -> A(1423) -> S'(1424) Reward : \u001b[4m2.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1424) -> A(1426) -> S'(1428) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1428) -> A(1430) -> S'(1431) Reward : \u001b[4m-3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1431) -> A(1435) -> S'(1436) Reward : \u001b[4m1.25\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1436) -> A(1437) -> S'(1441) Reward : \u001b[4m-2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1441) -> A(1442) -> S'(1446) Reward : \u001b[4m-2.222\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1446) -> A(1447) -> S'(1452) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1452) -> A(1455) -> S'(1458) Reward : \u001b[4m-1.818\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1458) -> A(1461) -> S'(1465) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1465) -> A(1467) -> S'(1472) Reward : \u001b[4m0.714\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1472) -> A(1478) -> S'(1479) Reward : \u001b[4m0.667\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  263.9643394947052 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 25 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(82) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(82) -> A(84) -> S'(88) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(88) -> A(91) -> S'(1480) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1480) -> A(1482) -> S'(1486) Reward : \u001b[4m2.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1486) -> A(1490) -> S'(1491) Reward : \u001b[4m1.667\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1491) -> A(1492) -> S'(1495) Reward : \u001b[4m-3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1495) -> A(1499) -> S'(1500) Reward : \u001b[4m-2.857\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1500) -> A(1505) -> S'(1506) Reward : \u001b[4m1.111\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1506) -> A(1510) -> S'(1512) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1512) -> A(1513) -> S'(1516) Reward : \u001b[4m0.909\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1516) -> A(1517) -> S'(1521) Reward : \u001b[4m-1.818\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1521) -> A(1522) -> S'(1526) Reward : \u001b[4m-1.667\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1526) -> A(1527) -> S'(1532) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1532) -> A(1536) -> S'(1538) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  264.90224266052246 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 26 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(4) -> S'(205) Reward : \u001b[4m5.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(205) -> A(206) -> S'(633) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(633) -> A(637) -> S'(1539) Reward : \u001b[4m2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1539) -> A(1542) -> S'(1545) Reward : \u001b[4m-5.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1545) -> A(1549) -> S'(1551) Reward : \u001b[4m1.667\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1551) -> A(1555) -> S'(1557) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1557) -> A(1558) -> S'(1562) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1562) -> A(1564) -> S'(1566) Reward : \u001b[4m-2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1566) -> A(1567) -> S'(1571) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1571) -> A(1574) -> S'(1576) Reward : \u001b[4m0.909\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1576) -> A(1578) -> S'(1581) Reward : \u001b[4m0.833\u001b[0m\n",
      "##########['cereal0', 'bottle0', 'can0', 'ben_cube0']#############\n",
      "\u001b[94mSuccess!!!!!\u001b[0m\n",
      "Terminal State! Reward is 5\n",
      "already has grasp_poses\n",
      "already has grasp_poses\n",
      "\u001b[0;33mcereal0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 79 grasps for object cereal0\n",
      "solve with LM1\n",
      "Iterators : 7\n",
      "WorkingTime[inverse_kinematics]: 0.0035 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0016 sec\n",
      "\n",
      "\u001b[0;33mbottle0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 78 grasps for object bottle0\n",
      "solve with LM1\n",
      "Iterators : 12\n",
      "WorkingTime[inverse_kinematics]: 0.0058 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0027 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 58 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 20\n",
      "WorkingTime[inverse_kinematics]: 0.0094 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 100\n",
      "WorkingTime[inverse_kinematics]: 0.0438 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 100\n",
      "WorkingTime[inverse_kinematics]: 0.0435 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 100\n",
      "WorkingTime[inverse_kinematics]: 0.0437 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 100\n",
      "WorkingTime[inverse_kinematics]: 0.0436 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 100\n",
      "WorkingTime[inverse_kinematics]: 0.0446 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 10\n",
      "WorkingTime[inverse_kinematics]: 0.0048 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 7\n",
      "WorkingTime[inverse_kinematics]: 0.0034 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "\u001b[0;33mbottle0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 86 grasps for object bottle0\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0045 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "\u001b[0;33mben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 3 grasps for object ben_cube0\n",
      "solve with LM1\n",
      "Iterators : 13\n",
      "WorkingTime[inverse_kinematics]: 0.0063 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0025 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0017 sec\n",
      "\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 98 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 24\n",
      "WorkingTime[inverse_kinematics]: 0.0111 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 100\n",
      "WorkingTime[inverse_kinematics]: 0.0436 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 100\n",
      "WorkingTime[inverse_kinematics]: 0.0435 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 100\n",
      "WorkingTime[inverse_kinematics]: 0.0434 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 100\n",
      "WorkingTime[inverse_kinematics]: 0.0436 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 84\n",
      "WorkingTime[inverse_kinematics]: 0.0379 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0043 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 3\n",
      "WorkingTime[inverse_kinematics]: 0.0016 sec\n",
      "\n",
      "\u001b[0;33mben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 17 grasps for object ben_cube0\n",
      "solve with LM1\n",
      "Iterators : 10\n",
      "WorkingTime[inverse_kinematics]: 0.0050 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0023 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0021 sec\n",
      "\n",
      "\u001b[0;33mcan0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 10 grasps for object can0\n",
      "Augment 2 y axis rotation from -pi/3 ~ pi/3 :  (60, 4, 4)\n",
      "Collision free grasps step 3 :  (0,)\n",
      "\u001b[0;31mfailed to generate grasp pose for can0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 117 grasps for object can0\n",
      "solve with LM1\n",
      "Iterators : 17\n",
      "WorkingTime[inverse_kinematics]: 0.0080 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 5\n",
      "WorkingTime[inverse_kinematics]: 0.0026 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0043 sec\n",
      "\n",
      "\u001b[0;33mben_cube0\u001b[0m\n",
      "Extracted Region Cube Size:  0.4\n",
      "Generated 12 grasps for object ben_cube0\n",
      "solve with LM1\n",
      "Iterators : 15\n",
      "WorkingTime[inverse_kinematics]: 0.0070 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 10\n",
      "WorkingTime[inverse_kinematics]: 0.0047 sec\n",
      "\n",
      "solve with LM1\n",
      "Iterators : 13\n",
      "WorkingTime[inverse_kinematics]: 0.0060 sec\n",
      "\n",
      "\u001b[91mA value of this optimal nodes is lower than maximum value.\u001b[0m\n",
      "\u001b[95m level 2 value : 14.931767 \u001b[0m\n",
      "Add level_1_node!\n",
      "########### Running time :  269.22603011131287 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 27 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(82) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(82) -> A(85) -> S'(577) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(577) -> A(580) -> S'(1582) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1582) -> A(1587) -> S'(1588) Reward : \u001b[4m2.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1588) -> A(1590) -> S'(1594) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1594) -> A(1596) -> S'(1599) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1599) -> A(1600) -> S'(1604) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1604) -> A(1607) -> S'(1610) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1610) -> A(1614) -> S'(1615) Reward : \u001b[4m-2.222\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1615) -> A(1618) -> S'(1622) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1622) -> A(1624) -> S'(1629) Reward : \u001b[4m0.833\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1629) -> A(1630) -> S'(1635) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1635) -> A(1637) -> S'(1640) Reward : \u001b[4m0.714\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1640) -> A(1641) -> S'(1646) Reward : \u001b[4m-1.429\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  270.12399339675903 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 28 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(4) -> S'(205) Reward : \u001b[4m5.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(205) -> A(207) -> S'(650) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(650) -> A(654) -> S'(1647) Reward : \u001b[4m2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1647) -> A(1650) -> S'(1652) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1652) -> A(1655) -> S'(1656) Reward : \u001b[4m-4.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1656) -> A(1657) -> S'(1661) Reward : \u001b[4m-3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1661) -> A(1666) -> S'(1667) Reward : \u001b[4m1.25\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1667) -> A(1669) -> S'(1673) Reward : \u001b[4m1.111\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1673) -> A(1675) -> S'(1678) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1678) -> A(1679) -> S'(1681) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1681) -> A(1685) -> S'(1686) Reward : \u001b[4m-1.818\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1686) -> A(1688) -> S'(1692) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1692) -> A(1695) -> S'(1698) Reward : \u001b[4m0.714\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1698) -> A(1702) -> S'(1703) Reward : \u001b[4m0.667\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  271.2968626022339 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 29 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(1) -> S'(82) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(82) -> A(84) -> S'(88) Reward : \u001b[4m3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(88) -> A(92) -> S'(1704) Reward : \u001b[4m2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1704) -> A(1705) -> S'(1710) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1710) -> A(1711) -> S'(1715) Reward : \u001b[4m-4.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1715) -> A(1718) -> S'(1721) Reward : \u001b[4m-3.333\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1721) -> A(1727) -> S'(1728) Reward : \u001b[4m1.25\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1728) -> A(1732) -> S'(1734) Reward : \u001b[4m1.111\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1734) -> A(1736) -> S'(1740) Reward : \u001b[4m1.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1740) -> A(1743) -> S'(1744) Reward : \u001b[4m-2.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1744) -> A(1748) -> S'(1749) Reward : \u001b[4m0.833\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1749) -> A(1750) -> S'(1754) Reward : \u001b[4m-1.667\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1754) -> A(1757) -> S'(1759) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1759) -> A(1761) -> S'(1764) Reward : \u001b[4m0.667\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  272.2042281627655 ##############\n",
      "\n",
      "[1/10] Benchmark: 0, Algo: bai_perturb, C: 2.5, Seed: 22\n",
      "\u001b[95m=========== Search iteration : 30 ===========\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(0) -> A(4) -> S'(205) Reward : \u001b[4m5.0\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(205) -> A(206) -> S'(633) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(633) -> A(636) -> S'(638) Reward : \u001b[4m2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(638) -> A(639) -> S'(1765) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1765) -> A(1768) -> S'(1770) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr ben_cube0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1770) -> A(1772) -> S'(1774) Reward : \u001b[4m1.429\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1774) -> A(1775) -> S'(1779) Reward : \u001b[4m-2.857\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1779) -> A(1780) -> S'(1783) Reward : \u001b[4m-2.5\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1783) -> A(1785) -> S'(1789) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1789) -> A(1793) -> S'(1794) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1794) -> A(1796) -> S'(1799) Reward : \u001b[4m0.833\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr can0\u001b[0m\n",
      "\u001b[0;34mplaced another place not goal\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1799) -> A(1800) -> S'(1804) Reward : \u001b[4m-1\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr bottle0\u001b[0m\n",
      "\u001b[91mBad Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1804) -> A(1806) -> S'(1809) Reward : \u001b[4m-1.538\u001b[0m\n",
      "\u001b[0;33m[Action]\u001b[0m \u001b[92mRearr cereal0\u001b[0m\n",
      "\u001b[0;36mGood Action\u001b[0m\n",
      "\u001b[95m[Reward]\u001b[0m S(1809) -> A(1814) -> S'(1815) Reward : \u001b[4m0.667\u001b[0m\n",
      "\u001b[93mExceeded the maximum depth!!\u001b[0m\n",
      "########### Running time :  273.062381029129 ##############\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for i in range(budgets):\n",
    "# for i in range(10):\n",
    "    print(\n",
    "        f\"\\n[{idx+1}/{len(c_list)}] Benchmark: {rearrangement1.scene_mngr.scene.bench_num}, Algo: {algo}, C: {c}, Seed: {seed}\"\n",
    "    )\n",
    "    mcts.do_planning_rearrange(i)\n",
    "\n",
    "    print(\"########### Running time : \", time.time()- start_time, \"##############\")\n",
    "    final_level_1_values.append(mcts.values_for_level_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16942014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.666666666666668 {0: {'nodes': [0, 1, 82, 84, 88, 93, 95, 100, 101, 102, 107, 110, 112, 114, 117, 121, 122], 'value': 7.894444444444446}, 1: {'nodes': [0, 4, 205, 210, 212, 217, 218, 221, 224, 225, 230, 233, 236, 237, 243, 245, 248, 250, 254, 258, 260, 264, 265, 269, 270], 'value': 2.6803418803418824}, 2: {'nodes': [0, 1, 82, 85, 577, 581, 583, 585, 590, 593, 596, 598, 600, 603, 604, 608, 609, 612, 614, 615, 618, 620, 623, 625, 628, 631, 632], 'value': 2.604151404151403}, 3: {'nodes': [0, 4, 205, 206, 633, 636, 638, 640, 644, 648, 649], 'value': 14.666666666666668}, 4: {'nodes': [0, 4, 205, 207, 650, 653, 655, 656, 658, 661, 662, 666, 667, 670, 671], 'value': 12.811904761904762}, 5: {'nodes': [0, 4, 205, 206, 633, 634, 1074, 1080, 1081, 1086, 1088, 1092, 1094, 1095, 1100, 1104, 1105, 1106, 1111, 1113, 1115, 1117, 1121, 1124, 1127, 1130, 1131], 'value': 0.27875457875457954}, 6: {'nodes': [0, 4, 205, 207, 650, 651, 1199, 1203, 1205, 1209, 1210, 1213, 1216, 1217, 1220, 1221, 1225, 1227, 1230, 1234, 1236, 1238, 1241, 1245, 1246], 'value': 3.8073260073260085}, 7: {'nodes': [0, 4, 205, 206, 633, 637, 1539, 1542, 1545, 1549, 1551, 1555, 1557, 1558, 1562, 1564, 1566, 1567, 1571, 1574, 1576, 1578, 1581], 'value': 5.737662337662338}}\n",
      "\n",
      "Result 3 :  [0, 4, 205, 206, 633, 636, 638, 640, 644, 648, 649]\n",
      "state num : 11\n"
     ]
    }
   ],
   "source": [
    "max_level_1_value = mcts.get_max_value_level_1()\n",
    "print(max_level_1_value, mcts.history_level_1_dict)\n",
    "\n",
    "########## level 1 ##########\n",
    "if mcts.history_level_1_dict:\n",
    "    j, max_value_nodes = mcts.get_max_value_nodes_level_1()\n",
    "    print()\n",
    "    print(f\"Result {j} : \", max_value_nodes)\n",
    "    print(\"state num :\", len(max_value_nodes))\n",
    "#     mcts.render_rearr(\"_\", max_value_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "143197e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'nodes': [0,\n",
       "   1,\n",
       "   82,\n",
       "   84,\n",
       "   88,\n",
       "   93,\n",
       "   95,\n",
       "   100,\n",
       "   101,\n",
       "   102,\n",
       "   107,\n",
       "   110,\n",
       "   112,\n",
       "   114,\n",
       "   117,\n",
       "   121,\n",
       "   122],\n",
       "  'value': 8.256744},\n",
       " 1: {'nodes': [0, 4, 205, 206, 633, 636, 638, 640, 644, 648, 649],\n",
       "  'value': 14.931767}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcts.history_level_2_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c2739e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  4,\n",
       "  205,\n",
       "  210,\n",
       "  212,\n",
       "  217,\n",
       "  218,\n",
       "  221,\n",
       "  224,\n",
       "  225,\n",
       "  230,\n",
       "  233,\n",
       "  236,\n",
       "  237,\n",
       "  243,\n",
       "  245,\n",
       "  248,\n",
       "  250,\n",
       "  254,\n",
       "  258,\n",
       "  260,\n",
       "  264,\n",
       "  265,\n",
       "  269,\n",
       "  270]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcts.infeasible_sub_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d20d85",
   "metadata": {},
   "source": [
    "## 실패를 했음. 그 와중에 Level 1.5는 다 생성했음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19ae3fe9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes [0, 1, 82, 85, 561, 563, 1340, 1345, 1346, 1348, 1351, 1352, 1356, 1360, 1362, 1366, 1368, 1370, 1373]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_level_1_value = mcts.get_max_value_level_1()\n",
    "\n",
    "\n",
    "fig, ax = p_utils.init_3d_figure(name=\"Level wise 1\")\n",
    "\n",
    "# nodes = mcts.infeasible_sub_nodes[0]\n",
    "nodes = mcts.history_level_1_dict[4]['nodes']\n",
    "\n",
    "print(\"nodes\", nodes)\n",
    "i = 0\n",
    "for i in range(len(nodes)//2):\n",
    "    mcts.rearr_action.deepcopy_scene(mcts.tree.nodes[nodes[2*(i)+1]]['state'])\n",
    "\n",
    "    grasp = mcts.tree.nodes[nodes[2*(i)+1]]['grasp_set'][0]\n",
    "    mcts.rearr_action.scene_mngr.set_gripper_pose(grasp)\n",
    "\n",
    "\n",
    "    gripper_kinematics_info = mcts.rearr_action.scene_mngr.scene.robot.gripper.get_gripper_fk()\n",
    "\n",
    "    gripper_tip_poses = mcts.scene_mngr.scene.robot.gripper.compute_gripper_tip_pose_from_gripper_pose()\n",
    "\n",
    "\n",
    "    mcts.rearr_action.scene_mngr.render_axis(ax, gripper_kinematics_info['leftfinger'])\n",
    "    mcts.rearr_action.scene_mngr.render_axis(ax, gripper_kinematics_info['rightfinger'])\n",
    "    mcts.rearr_action.scene_mngr.render_axis(ax, mcts.scene_mngr.scene.robot.gripper.compute_gripper_tip_pose_from_gripper_pose(gripper_kinematics_info['rightfinger']))\n",
    "    mcts.rearr_action.scene_mngr.render_axis(ax, mcts.scene_mngr.scene.robot.gripper.compute_gripper_tip_pose_from_gripper_pose(gripper_kinematics_info['leftfinger']))\n",
    "\n",
    "    mcts.rearr_action.scene_mngr.render_axis(ax, mcts.rearr_action.scene_mngr.scene.robot.gripper.get_gripper_tcp_pose())\n",
    "    mcts.rearr_action.scene_mngr.render_gripper(ax)\n",
    "\n",
    "    mcts.rearr_action.scene_mngr.render_objects(ax)\n",
    "    p_utils.plot_basis(ax)\n",
    "    mcts.rearr_action.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "696f13a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  7,\n",
       "  446,\n",
       "  450,\n",
       "  452,\n",
       "  455,\n",
       "  458,\n",
       "  461,\n",
       "  463,\n",
       "  465,\n",
       "  469,\n",
       "  470,\n",
       "  475,\n",
       "  478,\n",
       "  480,\n",
       "  481,\n",
       "  485,\n",
       "  487,\n",
       "  490,\n",
       "  494,\n",
       "  495,\n",
       "  497,\n",
       "  500,\n",
       "  503,\n",
       "  504]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcts.infeasible_sub_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39ce712",
   "metadata": {},
   "source": [
    "각 node에서 생성한 grasp을 inverse kinematics를 풀어보자 \n",
    "\n",
    "\n",
    "엄청 쉬워보이는 자세인데 왜 IK 실패를 할까"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edd3cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_curernt_scene(q, pose):\n",
    "    fig, ax = p_utils.init_3d_figure(name=\"Level wise 1\")\n",
    "    \n",
    "    mcts.rearr_action.scene_mngr.set_robot_eef_pose(q)\n",
    "    mcts.rearr_action.scene_mngr.render_axis(ax, mcts.rearr_action.scene_mngr.scene.robot.gripper.get_gripper_pose())\n",
    "    mcts.rearr_action.scene_mngr.render_gripper(ax)\n",
    "    \n",
    "    mcts.rearr_action.scene_mngr.set_gripper_pose(pose)\n",
    "    mcts.rearr_action.scene_mngr.render_axis(ax, mcts.rearr_action.scene_mngr.scene.robot.gripper.get_gripper_pose())\n",
    "    mcts.rearr_action.scene_mngr.render_gripper(ax)\n",
    "\n",
    "    mcts.rearr_action.scene_mngr.render_objects(ax)\n",
    "    p_utils.plot_basis(ax)\n",
    "    mcts.rearr_action.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "205898e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'current_state_node' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcurrent_state_node\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'current_state_node' is not defined"
     ]
    }
   ],
   "source": [
    "current_state_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1e5eac2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'table': \u001b[95mObject\u001b[0m(name=table, pos=[ 0.9   -0.6    0.043]),\n",
       " 'ben_cube0': \u001b[95mObject\u001b[0m(name=ben_cube0, pos=[ 0.55993829 -0.00222162  0.83529998]),\n",
       " 'bottle0': \u001b[95mObject\u001b[0m(name=bottle0, pos=[ 0.34645189 -0.27510566  0.87515735]),\n",
       " 'can0': \u001b[95mObject\u001b[0m(name=can0, pos=[0.37967303 0.22550238 0.85059666]),\n",
       " 'cereal0': \u001b[95mObject\u001b[0m(name=cereal0, pos=[0.42014769 0.00883087 0.88526188])}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_action_node['state'].objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7b65d509",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': 5,\n",
       " 'state': <pytamp.scene.scene.Scene at 0x7f38d0590ac0>,\n",
       " 'action': {'type': 'rearr',\n",
       "  'rearr_obj_name': 'ben_cube0',\n",
       "  'place_obj_name': 'table',\n",
       "  'rearr_poses': [{'table': array([[ 0.45999483,  0.8879216 ,  0.        ,  0.47189415],\n",
       "           [-0.8879216 ,  0.45999483,  0.        , -0.22862241],\n",
       "           [ 0.        ,  0.        ,  1.        ,  0.83529998],\n",
       "           [ 0.        ,  0.        ,  0.        ,  1.        ]])}]},\n",
       " 'value': 2.6525641025641034,\n",
       " 'value_history': [2.6525641025641034],\n",
       " 'visit': 1,\n",
       " 'number': 465,\n",
       " 'type': 'action',\n",
       " 'joints': [],\n",
       " 'level1': True,\n",
       " 'level2': False,\n",
       " 'level1_5': True,\n",
       " 'success': False,\n",
       " 'cost': 0,\n",
       " 'test': (),\n",
       " 'grasp_set': array([[[-9.57802589e-01,  1.60181513e-01, -2.38654931e-01,\n",
       "           5.90741910e-01],\n",
       "         [ 1.76931649e-01,  9.82934117e-01, -5.03560342e-02,\n",
       "          -6.25361523e-04],\n",
       "         [ 2.26515987e-01, -9.04567494e-02, -9.69797992e-01,\n",
       "           9.35301307e-01],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           1.00000000e+00]],\n",
       " \n",
       "        [[-7.38329714e-01,  6.16220317e-01,  2.74119889e-01,\n",
       "           5.37090383e-01],\n",
       "         [ 5.79419971e-01,  7.87563980e-01, -2.09798560e-01,\n",
       "           1.65383436e-02],\n",
       "         [-3.45169076e-01,  3.92999343e-03, -9.38532278e-01,\n",
       "           9.41457448e-01],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           1.00000000e+00]],\n",
       " \n",
       "        [[ 9.66689100e-01, -2.59206598e-02,  2.54637643e-01,\n",
       "           5.35114348e-01],\n",
       "         [-1.99706536e-02, -9.99464452e-01, -2.59244535e-02,\n",
       "           1.27085594e-03],\n",
       "         [ 2.55173289e-01,  1.99756872e-02, -9.66688940e-01,\n",
       "           9.42144133e-01],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           1.00000000e+00]],\n",
       " \n",
       "        [[-9.70875950e-01,  4.43590574e-02, -2.35440588e-01,\n",
       "           5.72305016e-01],\n",
       "         [ 5.21842390e-02,  9.98269558e-01, -2.71072052e-02,\n",
       "          -7.78102151e-04],\n",
       "         [ 2.33830749e-01, -3.86039881e-02, -9.71510638e-01,\n",
       "           9.52180343e-01],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           1.00000000e+00]],\n",
       " \n",
       "        [[-9.81201209e-01,  1.44487448e-01,  1.27934667e-01,\n",
       "           5.37057775e-01],\n",
       "         [ 1.36964083e-01,  9.88387048e-01, -6.58161119e-02,\n",
       "          -1.29156581e-04],\n",
       "         [-1.35958590e-01, -4.70564136e-02, -9.89596232e-01,\n",
       "           9.35964177e-01],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           1.00000000e+00]]]),\n",
       " 'grasp_poses': [{'grasp': array([[-9.57802589e-01,  1.60181513e-01, -2.38654931e-01,\n",
       "            5.90741910e-01],\n",
       "          [ 1.76931649e-01,  9.82934117e-01, -5.03560342e-02,\n",
       "           -6.25361523e-04],\n",
       "          [ 2.26515987e-01, -9.04567494e-02, -9.69797992e-01,\n",
       "            9.35301307e-01],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "            1.00000000e+00]]),\n",
       "   'pre_grasp': array([[-0.9578026 ,  0.16018151, -0.23865493,  0.60267466],\n",
       "          [ 0.17693165,  0.9829341 , -0.05035603,  0.00189244],\n",
       "          [ 0.226516  , -0.09045675, -0.96979797,  0.98379123],\n",
       "          [ 0.        ,  0.        ,  0.        ,  1.        ]],\n",
       "         dtype=float32),\n",
       "   'post_grasp': array([[-9.5780259e-01,  1.6018151e-01, -2.3865493e-01,  5.9074193e-01],\n",
       "          [ 1.7693165e-01,  9.8293412e-01, -5.0356034e-02, -6.2536151e-04],\n",
       "          [ 2.2651599e-01, -9.0456747e-02, -9.6979797e-01,  9.8530132e-01],\n",
       "          [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "         dtype=float32)}]}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_action_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a50c26b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state node num :  82\n",
      "Current state is came from last action\n",
      "[[-0.95959836  0.1365453  -0.24602118  0.60479504]\n",
      " [ 0.15776686  0.9850888  -0.06862646  0.0046475 ]\n",
      " [ 0.2329821  -0.10466783 -0.966832    0.99195665]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "rearr_obj_name :  ben_cube0\n",
      "default 부터 Pre grasp까지 IK 품\n",
      "solve with LM1\n",
      "Iterators : 9\n",
      "WorkingTime[inverse_kinematics]: 0.0137 sec\n",
      "\n",
      "pre_grasp 부터 grasp까지 IK 품\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0094 sec\n",
      "\n",
      "grasp 부터 post_grasp까지 IK 품\n",
      "solve with LM1\n",
      "Iterators : 4\n",
      "WorkingTime[inverse_kinematics]: 0.0123 sec\n",
      "\n",
      "default 부터 post_release까지 IK 품\n",
      "solve with LM1\n",
      "Iterators : 13\n",
      "WorkingTime[inverse_kinematics]: 0.0139 sec\n",
      "\n",
      "release 부터 post_release까지 IK 품\n",
      "solve with LM1\n",
      "Iterators : 7\n",
      "WorkingTime[inverse_kinematics]: 0.0122 sec\n",
      "\n",
      "post_release 부터 post_release까지 IK 품\n",
      "solve with LM1\n",
      "Iterators : 0\n",
      "WorkingTime[inverse_kinematics]: 0.0032 sec\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "default_thetas = mcts.rearr_action.scene_mngr.scene.robot.init_qpos\n",
    "\n",
    "for _, i in enumerate(nodes):\n",
    "    if _ < 1:\n",
    "        continue\n",
    "    if _%2 == 1:\n",
    "        continue\n",
    "        \n",
    "    print(\"Current state node num : \",i)\n",
    "    print(\"Current state is came from last action\")\n",
    "    \n",
    "    mcts.rearr_action.deepcopy_scene(mcts.tree.nodes[nodes[2*_+1]]['state'])\n",
    "\n",
    "    last_action_node = mcts.tree.nodes[nodes[2*_+1]]\n",
    "    current_state_node = mcts.tree.nodes[i]\n",
    "    \n",
    "    print(current_state_node['action']['pre_grasp'])\n",
    "    pre_grasp_pose = current_state_node['action']['pre_grasp']\n",
    "    grasp_pose = current_state_node['action']['grasp']\n",
    "    post_grasp_pose = current_state_node['action']['post_grasp']\n",
    "    \n",
    "    pre_release_pose = current_state_node['action']['pre_release']\n",
    "    release_pose = current_state_node['action']['release']\n",
    "    post_release_pose = current_state_node['action']['post_release']\n",
    "    \n",
    "    obj_release_pose = current_state_node['action']['table']\n",
    "    # Set Scene\n",
    "    mcts.rearr_action.scene_mngr.set_robot_eef_pose(default_thetas)\n",
    "    rearr_obj_name = current_state_node['state'].rearr_obj_name\n",
    "    rearr_default_pose = current_state_node['state'].rearr_obj_default_pose\n",
    "    print(\"rearr_obj_name : \", rearr_obj_name)\n",
    "    \n",
    "    mcts.rearr_action.scene_mngr.set_object_pose(rearr_obj_name, rearr_default_pose)\n",
    "\n",
    "    show_curernt_scene(default_thetas ,pre_grasp_pose)\n",
    "    print(\"default 부터 Pre grasp까지 IK 품\")\n",
    "    \n",
    "    goal_q = mcts.rearr_action.scene_mngr.scene.robot.inverse_kin(\n",
    "            default_thetas, pre_grasp_pose, max_iter=100\n",
    "        )\n",
    "    \n",
    "    show_curernt_scene(goal_q, grasp_pose)\n",
    "    print(\"pre_grasp 부터 grasp까지 IK 품\")\n",
    "    goal_q = mcts.rearr_action.scene_mngr.scene.robot.inverse_kin(\n",
    "        goal_q, grasp_pose, max_iter=100\n",
    "    )\n",
    "    \n",
    "    show_curernt_scene(goal_q, post_grasp_pose)\n",
    "    print(\"grasp 부터 post_grasp까지 IK 품\")\n",
    "    goal_q = mcts.rearr_action.scene_mngr.scene.robot.inverse_kin(\n",
    "        goal_q, post_grasp_pose, max_iter=100\n",
    "    )\n",
    "    \n",
    "    mcts.rearr_action.scene_mngr.set_robot_eef_pose(default_thetas)\n",
    "\n",
    "    mcts.rearr_action.scene_mngr.set_object_pose(rearr_obj_name, obj_release_pose)\n",
    "\n",
    "    show_curernt_scene(default_thetas, post_release_pose)\n",
    "    print(\"default 부터 post_release까지 IK 품\")\n",
    "    goal_q = mcts.rearr_action.scene_mngr.scene.robot.inverse_kin(\n",
    "        default_thetas, pre_release_pose, max_iter=100\n",
    "    )\n",
    "    \n",
    "    show_curernt_scene(goal_q, release_pose)\n",
    "    print(\"release 부터 post_release까지 IK 품\")\n",
    "    goal_q = mcts.rearr_action.scene_mngr.scene.robot.inverse_kin(\n",
    "        goal_q, release_pose, max_iter=100\n",
    "    )\n",
    "    \n",
    "    show_curernt_scene(goal_q, post_release_pose)\n",
    "    print(\"post_release 부터 post_release까지 IK 품\")\n",
    "    goal_q = mcts.rearr_action.scene_mngr.scene.robot.inverse_kin(\n",
    "        goal_q, release_pose, max_iter=100\n",
    "    )\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92655f3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bottle0'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mcts.tree.nodes[mcts.infeasible_sub_nodes[0][2*_ + 2]]['state']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdbb3c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a5676d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5060b789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71030c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06f645a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e2b2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0f30d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51fb47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1629c7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbcda06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d5231b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ba30f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d588b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c918c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17c59f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1284ded7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b662a1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dd581a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e3da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b4407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cdb60b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55c939b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b64ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50f45ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contact_graspnet",
   "language": "python",
   "name": "contact_graspnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
